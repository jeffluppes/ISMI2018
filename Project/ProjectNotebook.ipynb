{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISMI2018 Lymphocyte Detection Project\n",
    "This is the main notebook for the final ISMI2018 project by Group 6.\n",
    "\n",
    "\n",
    "*Detection of lymphocytes in histopathology whole-slide images of breast, colon and prostate cancer, stained with immunohistochemistry*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team 6\n",
    "Our group consists out of four people:\n",
    "* **Brian Westerweel (Data Science)** - `B.Westerweel@student.ru.nl`\n",
    "* **Christoph Schmidl (Data Science)** - `c.schmidl@student.ru.nl`\n",
    "* **Gijs van der Meijde (Software Science)** - `G.vanderMeijde@student.ru.nl`\n",
    "* **Jeffrey Luppus (Data Science)** - `J.Luppes@student.ru.nl`\n",
    "\n",
    "*Supervisor: Francesco Ciompi*\n",
    "\n",
    "Group Github page: https://github.com/jeffluppes/ISMI2018 *feel free to work in branches.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```x``` = unavailable this date (e.g. unable to work on anything)\n",
    "* ```-``` = reduced availability (e.g. you might be able to skype or work a couple of hours)\n",
    "\n",
    "| Name  | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | *Notes* |\n",
    "|-------|---|---|---|---|---|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|---------|\n",
    "| Jeff  | - | - | x | x | x |  - |  - |  - |  - |    |  - |    |    |    |    |    |    |    |  x |    |    | *2 hrs a day for pet projects during work days, internship ends 15th* |\n",
    "| Gijs  | x | x | x | x | x |  x |  x |  x |  x |  x |  - |    |    |    |  - |  - |  - |    |    |    |    | *has short term deadline until the 13th*        |\n",
    "| Brian |   |   |   | - | - |  x |  x |  - |  - |  - |  - |  x |  x |  - |  - |  - |  - | x  |  x |  x |    |         |\n",
    "| Chris |   |   |   |   |   |    |    |    |    |    |    |    |    |    |    |    |    |    |    |    |    |         | \n",
    "\n",
    "I took Gijs's attendance from what he said this morning. Mine is based around my internship (ends the 15th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals for this week (June 4 to June 11)\n",
    "\n",
    "**MAIN GOALS**\n",
    "* Use all of the training and validation data that we have available\n",
    "* Store patches on disk so they do not need to be re-generated every time we boot up\n",
    "* Implement an upsampling method\n",
    "* Implement a function to return the coordinates of a mask (centroid calculation)\n",
    "* Saving predictions (images) to disk\n",
    "\n",
    "**Other goals:**\n",
    "\n",
    "* Implement loss plotting function\n",
    "* Implement early stopping\n",
    "* Implement a custom loss function\n",
    "* Run predictions on the entire validation set\n",
    "* Implement a function to generate a csv given a list with segmentation maps\n",
    "\n",
    "**Backlog and minor TODOs**\n",
    "* Implement image warping\n",
    "* Get data augmentation working\n",
    "* Implement a function to count lymphocytes\n",
    "\n",
    "Be aware of the following:\n",
    "\n",
    "* **Next contact moment**: Monday at 10 skype call > New moment to be scheduled\n",
    "* **Next group meeting**: Friday and Monday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Deadlines\n",
    "\n",
    "* ~~<font color='red'>**Mid-term presentation:** June 4, 9:00 - 12:00, room 616 Huygen building</font>~~\n",
    "* Deadline project: 25th of june\n",
    "* **Final presentation:** July 2, 9:00 - 12:00, room 616 Huygen building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "The two papers Francesco sent:\n",
    "\n",
    "* https://openreview.net/pdf?id=rk0xLisiM\n",
    "* https://openreview.net/pdf?id=S10IfW2oz\n",
    "\n",
    "Kaggle Contest about cell detection (Data Science Bowl 2018)\n",
    "\n",
    "* https://www.kaggle.com/c/data-science-bowl-2018\n",
    "\n",
    "Particular Kernels of Interest (KoIs)\n",
    "\n",
    "* https://www.kaggle.com/weiji14/yet-another-keras-u-net-data-augmentation\n",
    "* https://www.kaggle.com/piotrczapla/tensorflow-u-net-starter-lb-0-34\n",
    "* https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277?scriptVersionId=2164855\n",
    "\n",
    "Other resources\n",
    "\n",
    "* https://spark-in.me/post/unet-adventures-part-one-getting-acquainted-with-unet\n",
    "* https://towardsdatascience.com/medical-image-segmentation-part-1-unet-convolutional-networks-with-interactive-code-70f0f17f46c6 (Christoph)\n",
    "* https://colab.research.google.com/drive/1BgCDxVdVc0MAe_kC0waMGUV9ShcWW0hM (Christoph)\n",
    "* https://keunwoochoi.wordpress.com/2017/10/11/u-net-on-keras-2-0/ (Jeff)\n",
    "* https://github.com/jocicmarko/ultrasound-nerve-segmentation (Jeff)\n",
    "* https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/ (Gijs)\n",
    "\n",
    "### MOOCs if you have spare time to waste (I havent)\n",
    "http://course.fast.ai/part2.html\n",
    "http://course.fast.ai/lessons/lesson14.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# System\n",
    "from os.path import join, basename, dirname, exists  \n",
    "import os  \n",
    "from glob import glob\n",
    "import csv\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 2201136600 #because Pillow will whine to no end if you feed it big images. You're welcome.\n",
    "\n",
    "\n",
    "# Computational\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from matplotlib import pyplot as plt  \n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Flatten, Dropout, UpSampling2D, core\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Other\n",
    "from scipy.ndimage import imread  \n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Tracking time\n",
    "This tracks the computation time for the entire notebook. See results in the last cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'ruc0028' # Jeffrey = True\n",
    "#user = 'ruc0030' # Gijs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesius file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/train_images'\n",
    "validation_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/validation_images'\n",
    "test_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/test_images'\n",
    "train_points = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/training_annotations.csv'\n",
    "validation_points = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/validation_annotations.csv' #new\n",
    "data_dir = 'data'\n",
    "train_masks_dir = data_dir+'/train_masks'\n",
    "validation_masks_dir = data_dir+'/validation_masks'\n",
    "results_dir = 'Results'\n",
    "\n",
    "num_channels = 3  #changing this breaks the entire thing. \n",
    "\n",
    "gen_patches = False #Whether or not you want to generate new patches. Keep false to use patches stored on disk\n",
    "train_patches_dir = data_dir+'/train_patches'\n",
    "validation_patches_dir = data_dir+'/validation_patches'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the jupyter server runs locally (Brian, Gijs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttrain_dir = 'train_images'\n",
    "#ttrain_masks_dir = 'train_masks'\n",
    "#train_points = 'training_annotations.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Housekeeping\n",
    "This section defines the convenience methods needed for processing the images.\n",
    "\n",
    "* Creating various masks (used as ground truth)\n",
    "    * Square Masks\n",
    "    * Elipse Masks\n",
    "    * Circular Masks\n",
    "    * Mask creation\n",
    "* Creating patches\n",
    "    * Patch generation\n",
    "* Data augmentation generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    return x.split(', ')\n",
    "\n",
    "def createSquareMask(h, w, center, radius):\n",
    "    mask = np.zeros((h, w), dtype=bool)\n",
    "    lb = center[0] - radius\n",
    "    rb = center[0] + radius\n",
    "    ub = center[1] - radius\n",
    "    bb = center[1] + radius\n",
    "    mask[ub:bb, lb:rb] = True\n",
    "    return mask\n",
    "\n",
    "def createElipseMask(h, w, center, radius):\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + 2*(Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "\n",
    "def createCircularMask(h, w, center, radius):\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "    \n",
    "\n",
    "def createMaskForImage(img_dir, image_path, center_csv, mask_dir, mask_fn):\n",
    "    image_name = image_path.split('.png')[0]\n",
    "    image_id, roi = image_name.split('_ROI_')\n",
    "    print('Processing {}'.format(image_name))\n",
    "    \n",
    "    image = plt.imread(join(img_dir, image_path))\n",
    "    mask = np.zeros((image.shape[0], image.shape[1]))\n",
    "    pixel_size = 0.24309392273426056 # is this the same for each image?\n",
    "     \n",
    "    radius = 3.5 / pixel_size\n",
    "    \n",
    "    pois = []\n",
    "    with open(center_csv) as file:\n",
    "        pois = list(map(split, file.readlines()[1:]))\n",
    "    \n",
    "    pois = [poi for poi in pois if (poi[0] == image_id and poi[1] == roi)]\n",
    "\n",
    "    \n",
    "    print('Found {} lymphocytes in this image.'.format(len(pois))) # How many lymps are annotated here?\n",
    "    for poi in pois:\n",
    "        x = int(float(poi[3]))\n",
    "        y = int(float(poi[4]))\n",
    "        shape_mask = mask_fn(image.shape[0], image.shape[1], [x, y], radius)\n",
    "        mask[shape_mask] = 1\n",
    "        \n",
    "    mask_image = Image.fromarray(np.uint8(mask*255), 'L')\n",
    "    mask_image.save(join(mask_dir, image_name + '_nwmask.png'))\n",
    "    print('Created a mask for: {}'.format(image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 413 training images for patch generation.\n",
      "Processing 95-30827-5_CD3_ROI_3\n",
      "Found 226 lymphocytes in this image.\n",
      "Created a mask for: 95-30827-5_CD3_ROI_3\n",
      "Processing T3C03L1A2B1S11R01_ROI_1\n",
      "Found 282 lymphocytes in this image.\n",
      "Created a mask for: T3C03L1A2B1S11R01_ROI_1\n",
      "Processing 95-30827-5_CD3_ROI_5\n",
      "Found 349 lymphocytes in this image.\n",
      "Created a mask for: 95-30827-5_CD3_ROI_5\n",
      "Processing 12-CD3_27.11.2014_17.27.31_ROI_1\n",
      "Found 473 lymphocytes in this image.\n",
      "Created a mask for: 12-CD3_27.11.2014_17.27.31_ROI_1\n",
      "Processing T3C02L1A1B1S11R01_ROI_6\n",
      "Found 0 lymphocytes in this image.\n",
      "Created a mask for: T3C02L1A1B1S11R01_ROI_6\n",
      "Processing 37_CD3_ROI_1\n",
      "Found 842 lymphocytes in this image.\n",
      "Created a mask for: 37_CD3_ROI_1\n",
      "Processing T1C02L1A1B1S11R01_ROI_5\n",
      "Found 386 lymphocytes in this image.\n"
     ]
    }
   ],
   "source": [
    "training_paths = os.listdir(train_dir)\n",
    "mask_paths = os.listdir(train_masks_dir)\n",
    "print('Found {} training images for patch generation.'.format(len(training_paths))) # How many images do we actually have?\n",
    "for path in training_paths:\n",
    "    # Jeff note: locally I've renamed generated elipsismasks _emasks.png and square masks _smask.png\n",
    "    mask_name = path.split('.png')[0] + '_nwmask.png'\n",
    "    if mask_name not in mask_paths:\n",
    "        createMaskForImage(train_dir, path, train_points, train_masks_dir, createElipseMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Patch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function generates 1 random patch from patch_amount random images.\n",
    "\n",
    "def generate_patches(img_dir, msk_dir, patch_amount, width, height):\n",
    "    patches = []\n",
    "    all_img_paths = os.listdir(img_dir)\n",
    "    img_paths = random.sample(all_img_paths, patch_amount)\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "        msk_path = img_path.split('.png')[0] + '_mask.png'\n",
    "        img = imread(join(img_dir,img_path))\n",
    "        msk = imread(join(msk_dir, msk_path)) # changed june 1 to include params\n",
    "        msk = np.stack((msk,)*3, 2)\n",
    "\n",
    "        coord = getCoord(img, img_path, width, height, train_points)\n",
    "        if(coord != None):\n",
    "            patch = generate_patch(img,msk,width,height, coord)\n",
    "            patches.append(patch)\n",
    "            print(\"{}: {}  image: {}\".format(len(patches), patch[0].shape, msk_path))\n",
    "            print(\"{}: {}  mask:  {}\".format(len(patches), patch[1].shape, img_path))\n",
    "    while(len(patches) < patch_amount):\n",
    "        print(\"only {} out of {} patches could be generated, recursing now\".format(len(patches), patch_amount))\n",
    "        np.append(patches, generate_patches(img_dir, msk_dir, patch_amount - (len(patches) -1), width, height), axis=0)\n",
    "    return patches\n",
    "\n",
    "#This function generates a single random patch from an image.\n",
    "def generate_patch(img, msk, width, height, coord):\n",
    "    padHeight = 0 if height < img.shape[1] else height-img.shape[1]\n",
    "    padWidth  = 0 if width < img.shape[0] else width-img.shape[0]\n",
    "    if(img.shape[0] < width or img.shape[1] < height):\n",
    "        print(\"padding: {}x{}\".format(padWidth, padHeight))\n",
    "    img = np.pad(img, [(0,padWidth), (0, padHeight), (0,0 )], mode='constant')\n",
    "    msk = np.pad(msk, [(0,padWidth), (0, padHeight), (0,0 )], mode='constant')\n",
    "    #x = random.randint(0,img.shape[0]-width);\n",
    "    x = coord[0]\n",
    "    x1 = x + width\n",
    "    #y = random.randint(0,img.shape[1]-height);\n",
    "    y = coord[1]\n",
    "    y1 = y + height\n",
    "    if x1 > img.shape[0] or y1 > img.shape[1]:\n",
    "        print(\"WARNING x out of bounds ({} > {}) or y out of bounds ({} > {})\".format(x1,img.shape[0],y1,img.shape[1]))\n",
    "    return (np.array(img[x:x1,y:y1,:]), np.array(msk[x:x1,y:y1,:]))\n",
    "\n",
    "patch_log = []\n",
    "coord_tries = []\n",
    "def getCoord(img, img_path, width, height, csv_file):\n",
    "    img_name = img_path.split('.png')[0]\n",
    "    img_id, roi = img_name.split('_ROI_')\n",
    "    pois = []\n",
    "    \n",
    "    with open(csv_file) as file:\n",
    "        pois = list(map(split, file.readlines()[1:]))\n",
    "    pois = [poi for poi in pois if (poi[0] == img_id)]\n",
    "    while(len(coord_tries) < len(pois)):\n",
    "        #for poi in pois:\n",
    "        p = random.randint(0,len(pois)-1)\n",
    "        while(p in coord_tries):\n",
    "            p = random.randint(0,len(pois)-1)\n",
    "        coord_tries.append(p)\n",
    "        poi = pois[p]\n",
    "        x = int(float(poi[3]))\n",
    "        y = int(float(poi[4]))\n",
    "        if( (x,y) in patch_log):\n",
    "            return None\n",
    "        patch_log.append( (x,y) )\n",
    "        if(x - (width/2) >= 0 and x + (width/2) <= img.shape[0] and y - (height/2) >= 0 and y + (height/2) <= img.shape[1]):\n",
    "            return (round(x - (width/2)), round(y - (height/2)))\n",
    "    #poi = pois[np.random.choice(len(pois))]\n",
    "    return (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patches = generate_patches(train_dir, train_masks_dir, 200, 512, 512)\n",
    "mask_patches = []\n",
    "img_patches = []\n",
    "for patch in patches:\n",
    "    img_patches.append(np.array(patch[0]))\n",
    "    mask_patches.append(np.array(patch[1]))\n",
    "    \n",
    "#np.asarray(mask_patches)\n",
    "#np.asarray(img_patches)\n",
    "print(\"----------------------------\")\n",
    "print(\"{} image patches generated.\".format(len(img_patches)))\n",
    "print(\"{} mask patches generated.\".format(len(mask_patches)))\n",
    "print(\"img:  {}\".format(np.array(img_patches[0]).shape))\n",
    "print(\"mask: {}\".format(np.array(mask_patches[0]).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Augmentation\n",
    "*Not actually used at the moment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read images from disk and convert them to xyc format in a desire output range.\n",
    "def load_image(input_path, range_min=0, range_max=1):\n",
    "    \n",
    "    # Read image data (x, y, c) [0, 255]\n",
    "    image = Image.open(input_path)\n",
    "    \n",
    "    \n",
    "    half_the_width = image.size[0] / 2\n",
    "    half_the_height = image.size[1] / 2\n",
    "    image = image.crop(\n",
    "        (\n",
    "            half_the_width - 100,\n",
    "            half_the_height - 100,\n",
    "            half_the_width + 100,\n",
    "            half_the_height + 100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Convert image to the correct range\n",
    "    image = np.asarray(image) / 255\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define a function to plot a batch or list of image patches in a grid\n",
    "def plot_image(images, images_per_row=8):\n",
    "    \n",
    "    fig, axs = plt.subplots(int(np.ceil(len(images)/images_per_row)), images_per_row)\n",
    "    \n",
    "    c = 0\n",
    "    for ax_row in axs:\n",
    "        for ax in ax_row:\n",
    "            if c < len(images):\n",
    "                ax.imshow(images[c])\n",
    "            ax.axis('off')            \n",
    "            c += 1\n",
    "    plt.show()\n",
    "    \n",
    "training_paths = os.listdir(train_dir)\n",
    "validation_paths = os.listdir(validation_dir)\n",
    "\n",
    "training_images = [load_image(join(train_dir, path)) for path in training_paths[:50]]\n",
    "print('Some training examples (shape {shape}):'.format(shape=training_images[0].shape))\n",
    "plot_image(training_images[12:16], images_per_row=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=90,\n",
    "                                     horizontal_flip=True, \n",
    "                                     vertical_flip=True, \n",
    "                                     zoom_range=0.3, \n",
    "                                     width_shift_range=.3, \n",
    "                                     height_shift_range=.3)\n",
    "\n",
    "fake_labels = np.random.rand(len(training_images))\n",
    "fake_labels[fake_labels >= .5] = 1\n",
    "fake_labels[fake_labels < .5] = 0\n",
    "\n",
    "datagen.fit(training_images)\n",
    "\n",
    "for X_batch, y_batch in datagen.flow(np.array(training_images), fake_labels, batch_size=9):\n",
    "    plot_image(X_batch, images_per_row=3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Storing and getting patches \n",
    "Store everything in these objects to disk. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storepatchesondisk(patches, dirname):\n",
    "    #TODO\n",
    "    print('Patches stored!')\n",
    "\n",
    "def getpatchesfromdisk(dirname):\n",
    "    #TODO\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Upsampling\n",
    "TODO\n",
    "## 1.6 Calulate Centroids\n",
    "TODO\n",
    "## 1.7 Define custom callbacks\n",
    "TODO\n",
    "* Plot loss\n",
    "* early stopping\n",
    "\n",
    "## 1.8 Custom loss function\n",
    "TODO\n",
    "\n",
    "## 1.9 Image warping with OpenCV\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Networks\n",
    "This is where things go deep. The following two networks are defined\n",
    "\n",
    "* A \"stardard\" U-net that maxes out at 512\n",
    "* A copy of the U-net used to create a Retina U-net detector. Very specific approach and smaller than the standard u-net\n",
    "\n",
    "Additionally this section contains the following:\n",
    "* A method to calculate the f1-score\n",
    "* A method to save intermediate best networks\n",
    "* Some sanity checks: side-by-side plot of images and masks\n",
    "* Generating suitable training images\n",
    "* Model compilation \n",
    "* Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 U-net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_rows=512, img_cols=512, channels=3):\n",
    "    # A common problem is that Keras might automatically detect \"Channels first\" or last. The below notation is \"Channels last\"\n",
    "    # Which seems to be the default on cartesius. Problem, we only have once channel if we opt to only use the green channel\n",
    "    #\n",
    "    # Regarding input layer size - this does not seem to be our problem (Keras docs):\n",
    "    # When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers,\n",
    "    # does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in \n",
    "    # data_format=\"channels_last\".\n",
    "    \n",
    "    # So flattening also does not force the data into our format (e.g. by using a Flatten() layer)\n",
    "    \n",
    "    # Our error seems to be related to https://github.com/keras-team/keras/issues/6351 which includes many miracle fixes\n",
    "    # yet nothing for us.\n",
    "    \n",
    "    inputs = Input(shape=(img_rows, img_cols, channels))\n",
    "    s = keras.layers.core.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(s)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    " \n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    # we need to punish overfitting on background harshly until our model improves. Dice coef seems to get used often \n",
    "    # in literature, and kaggle. Using binary crossentropy for the moment. Before we were using categorical crossentropy\n",
    "    \n",
    "    sgd = keras.optimizers.SGD(lr=0.01) # Zanetta used 0.05, ours gets stuck in a local minimum and never improves. Probably related to training samples #\n",
    "    # however, we are now encountering this: a never changing loss and val_loss. \n",
    "    # https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 U-net based on Retina-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secondunet(img_rows=512, img_cols=512, channels=3):\n",
    "    inputs = Input(shape=(img_rows, img_cols, channels))\n",
    "    s = keras.layers.core.Lambda(lambda x: x / 255) (inputs)\n",
    "    # Unet taken fromDaniele Cortinovis Retina-net https://github.com/orobix/retina-unet\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(s)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    #\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    #\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv3)\n",
    "\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = concatenate([conv2,up1],axis=1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(up1)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv4)\n",
    "    #\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up2 = concatenate([conv1,up2], axis=1)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(up2)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv5)\n",
    "    #\n",
    "    conv6 = Conv2D(2, (1, 1), activation='relu',padding='same',data_format='channels_first')(conv5)\n",
    "    conv6 = core.Reshape((2,img_rows*img_cols))(conv6) \n",
    "    conv6 = core.Permute((2,1))(conv6)\n",
    "    ############\n",
    "    conv7 = core.Activation('softmax')(conv6)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv7)\n",
    "\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)\n",
    "    model.compile(optimizer='sgd', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network parameters, from Francesco's paper:\n",
    "\n",
    "* LR = 0.05\n",
    "* Dropouts 0.5 (when?)\n",
    "* SGD\n",
    "* CCR (cross-entropy) loss\n",
    "* F1-score\n",
    "\n",
    "* RGB threshold on training imgs\n",
    "\n",
    "Also 10 epochs with batch size 1. x20 resolution and 128x128 in- and output size \n",
    "\n",
    "## 2.3 F1-score\n",
    "f1-score based on what we had in week 7 or 8. Not used at the moment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    # Compute precision, recall and obtain several detection thresholds\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    \n",
    "    # Compute F1-score and remove numerical problems\n",
    "    f1 =  2 * (precision * recall) / (precision + recall)\n",
    "    f1 = f1[~np.isnan(f1)]\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Sanity check: plotting a patch and a corresponding mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(img_patches).shape) #should be (num_samples, 512, 512, 3)\n",
    "print(np.asarray(mask_patches).shape) #should be (num_samples, 512, 512)\n",
    "ino = 9\n",
    "\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "# for the record, matplotlib uses this short-hand notation to show subplots. The 121 here stands for 1 row, 2 columns, first img\n",
    "# now you know how to use subplots like a pro.\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_patches[ino])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_patches[ino])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 compile model and print model architecture. \n",
    "Also defines a model_checkpoint callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet(512, 512, num_channels)\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Prepare X_train and y_train sets\n",
    "* X_train contains the training samples (RGB)\n",
    "* y_train contains the labels as a binary map. Since the masks are generated as a 3-channel image earlier on, we just need to delete the two extra channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for img in img_patches:\n",
    "    X_train.append(np.asarray(img[:, :, :]))\n",
    "for msk in mask_patches:\n",
    "    y_train.append(np.asarray(msk[:, :,:]))\n",
    "\n",
    "y_train = np.delete(y_train, 2, 3)\n",
    "y_train = np.delete(y_train, 1, 3)\n",
    "\n",
    "#sanity checks.. what sizes are we dealing with?\n",
    "print(len(X_train))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Plot the mask again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate level sanity checks\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "# for the record, matplotlib uses this short-hand notation to show subplots. The 121 here stands for 1 row, 2 columns, first img\n",
    "# now you know how to use subplots like a pro.\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_patches[ino])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.squeeze(y_train[ino]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Finally train the model\n",
    "Train the model. If all goes well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One epoch generally takes 1 minute with batch size 1, 200 samples. Something to keep in mind..\n",
    "# the issues with the steady loss and val_loss seem to be related to the so-called dying relu problem. Go figure. Another problem to solve!\n",
    "# model.fit_generator(imgs_train, imgs_mask_train, batch_size=1, nb_epoch=10, verbose=1, shuffle=True, validation_split=0.2, callbacks=[model_checkpoint])\n",
    "model.fit(np.array(X_train), y_train, batch_size=8, epochs=5, verbose=1, shuffle=True, validation_split=0.1, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Using the Validation set for a sanity check\n",
    "The below code does the following things:\n",
    "\n",
    "* Load the best-yet model \n",
    "\n",
    "* load the validation images we've been supplied with\n",
    "* Generate masks for the validation images\n",
    "    * Creates a validation_masks_dir if there is none yet.\n",
    "    * Creates validation masks or loads them\n",
    "    * Creates patches for the validation set\n",
    "* Show side-by-side plots of the original validation image and the new mask\n",
    "\n",
    "* Shove one image in our best model and ask predict() what it makes out of it\n",
    "    * apply a threshold to the image\n",
    "* Plot the orgininal image, the defined mask, and the prediction side-by-side\n",
    "\n",
    "## 3.1 Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our best model\n",
    "model1 = keras.models.load_model('weights.h5') #saved by our callback earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Generate masks for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it does not exist already, create the validation masks folder\n",
    "validation_paths = os.listdir(validation_dir)\n",
    "if os.path.exists(validation_masks_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.system('mkdir -p ' + validation_masks_dir)\n",
    "\n",
    "# generate the masks if they are not already present on the system.\n",
    "mask_paths = os.listdir(validation_masks_dir)\n",
    "for path in validation_paths:\n",
    "    mask_name = path.split('.png')[0] + '_mask.png'\n",
    "    if mask_name not in mask_paths:\n",
    "        createMaskForImage(validation_dir, path, validation_points, validation_masks_dir, createCircularMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Generate patches for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vpatches = generate_patches(validation_dir, validation_masks_dir, 20, 512, 512)\n",
    "vmask_patches = []\n",
    "vimg_patches = []\n",
    "for patch in vpatches:\n",
    "    vimg_patches.append(np.array(patch[0]))\n",
    "    vmask_patches.append(np.array(patch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_p = []\n",
    "for img in vimg_patches:\n",
    "    val_images_p.append(np.asarray(img[:, :, :]))\n",
    "    \n",
    "#sanity checks.. what sizes are we dealing with?\n",
    "print(len(val_images_p))\n",
    "print(np.shape(val_images_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Check patches and masks from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show validation image and it's mask - Another sanity check\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "print(vimg_patches[0].shape)\n",
    "plt.imshow(vimg_patches[3])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(vmask_patches[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Make a prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "preds_val = model1.predict(np.asarray(val_images_p), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Threshold prediction\n",
    "May need to find a better way to do this at some point.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amin(preds_val)) # prints min\n",
    "print(np.ptp(preds_val)) # prints range\n",
    "print(np.amax(preds_val)) # prints max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold prediction\n",
    "preds_val = np.squeeze(preds_val) \n",
    "preds_val_t = (preds_val > 0.5)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amin(preds_val_t)) # prints min\n",
    "print(np.ptp(preds_val_t)) # prints range\n",
    "print(np.amax(preds_val_t)) # prints max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Checking prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check for checking image size\n",
    "print(np.shape(vimg_patches[0]))\n",
    "print(np.shape(preds_val[0])) \n",
    "print(np.shape(preds_val_t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subplot of 1 row\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "plt.suptitle('Example of a prediction on the validation set', fontsize=16)\n",
    "\n",
    "idx = 3 \n",
    "\n",
    "# plot original image\n",
    "plt.subplot(131)\n",
    "print(vimg_patches[idx].shape)\n",
    "plt.imshow(vimg_patches[idx])\n",
    "plt.title('Input data')\n",
    "\n",
    "#plot raw, unthresholded prediction\n",
    "plt.subplot(132)\n",
    "print(preds_val[idx].shape)\n",
    "plt.imshow(preds_val[idx])\n",
    "plt.title('Un-thresholded prediction')\n",
    "\n",
    "#plot thresholded prediction\n",
    "plt.subplot(133)\n",
    "plt.imshow(preds_val_t[idx], cmap='gray')\n",
    "plt.title('Thresholded Prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Prediction on the entire test set\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Writing results to disk\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir for results\n",
    "result_dir = 'Results'\n",
    "# Create directory for the results (if not already existing)\n",
    "if os.path.exists(result_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.system('mkdir -p ' + result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Preparing a submission\n",
    "TODO using the code provided. We need to decide how we are going to find the centroid. I think Francesco has more knowledge on algorithms for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Evaluation on the test set\n",
    "\n",
    "## 4.1 training on the training + validation set\n",
    "More data is more better. Lets take the validation set as training data for our final model and using a split of 0.1 or 0.2?\n",
    "\n",
    "Also worth to be considered is training on full images!\n",
    "\n",
    "## 4.2 Loading test images\n",
    "TODO\n",
    "\n",
    "## 4.3 Make predictions on the test images\n",
    "TODO\n",
    "\n",
    "## 4.4 Store test prediction images\n",
    "TODO\n",
    "\n",
    "## 4.5 Calculate Lymphocyte centroids\n",
    "TODO\n",
    "\n",
    "## 4.6 Convert predictions to a csv submission\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - What is outside the flow of work\n",
    "Counting the number of lymphocytes was the goal of the project although the evaluation is based on the precision of the network. Therefore the following method returns the number of lymphocytes, given a sample image. \n",
    "\n",
    "## 5.1 Counting Lymps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count the number of lymphocytes in a given image\n",
    "# TODO\n",
    "def count_lymps(image):\n",
    "    count = 0\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and other things that come up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.999 Print the time needed to execute the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Done in %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
