{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISMI2018 Lymphocyte Detection Project\n",
    "This is the main notebook for the final ISMI2018 project by Group 6.\n",
    "\n",
    "\n",
    "*Detection of lymphocytes in histopathology whole-slide images of breast, colon and prostate cancer, stained with immunohistochemistry*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team 6\n",
    "Our group consists out of four people:\n",
    "* **Brian Westerweel (Data Science)** - `B.Westerweel@student.ru.nl`\n",
    "* **Christoph Schmidl (Data Science)** - `c.schmidl@student.ru.nl`\n",
    "* **Gijs van der Meijde (Software Science)** - `G.vanderMeijde@student.ru.nl`\n",
    "* **Jeffrey Luppus (Data Science)** - `J.Luppes@student.ru.nl`\n",
    "\n",
    "*Supervisor: Francesco Ciompi*\n",
    "\n",
    "Group Github page: https://github.com/jeffluppes/ISMI2018 *feel free to work in branches.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```x``` = unavailable this date (e.g. unable to work on anything)\n",
    "* ```-``` = reduced availability (e.g. you might be able to skype or work a couple of hours)\n",
    "\n",
    "| Name  | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | *Notes* |\n",
    "|-------|---|---|---|---|---|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|---------|\n",
    "| Jeff  | - | - | x | x | x |  - |  - |  - |  - |    |  - |    |    |    |    |    |    |    |  x |    |    | *2 hrs a day for pet projects during work days, internship ends 15th* |\n",
    "| Gijs  | x | x | x | x | x |  x |  x |  x |  x |  x |  - |    |    |    |  - |  - |  - |    |    |    |    | *has short term deadline until the 13th*        |\n",
    "| Brian |   |   |   | - | - |  x |  x |  - |  - |  - |  - |  x |  x |  - |  - |  - |  - | x  |  x |  x |    |         |\n",
    "| Chris |   |   |   |   |   |    |  x |  x |  x |  x |    |    |    |    |  x |  x |  x |    |    |    |    |         | \n",
    "\n",
    "\n",
    "I took Gijs's attendance from what he said this morning. Mine is based around my internship (ends the 15th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals for this week (June 11 to June 18)\n",
    "\n",
    "**MAIN GOALS**\n",
    "* Use all of the training and validation data that we have available\n",
    "* Implement a function to return the coordinates of a mask (centroid calculation)\n",
    "* Saving predictions (images) to disk\n",
    "* Make a submission file\n",
    "* Use generator and make sensible augmentations\n",
    "* Make annotations\n",
    "* Make our first submission\n",
    "* Dont be lazy\n",
    "\n",
    "**Other goals:**\n",
    "\n",
    "* Implement loss plotting function\n",
    "* Implement early stopping\n",
    "* Implement a custom loss function\n",
    "* Run predictions on the entire validation set\n",
    "\n",
    "**Backlog and minor TODOs**\n",
    "* Implement image warping\n",
    "* Get data augmentation working\n",
    "* Implement a function to count lymphocytes\n",
    "\n",
    "Be aware of the following:\n",
    "\n",
    "* **Next contact moment**: Monday at 10 skype call > New moment to be scheduled\n",
    "* **Next group meeting**: Friday and Monday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Deadlines\n",
    "\n",
    "* ~~<font color='red'>**Mid-term presentation:** June 4, 9:00 - 12:00, room 616 Huygen building</font>~~\n",
    "* Deadline project: 25th of june\n",
    "* **Final presentation:** July 2, 9:00 - 12:00, room 616 Huygen building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "The two papers Francesco sent:\n",
    "\n",
    "* https://openreview.net/pdf?id=rk0xLisiM\n",
    "* https://openreview.net/pdf?id=S10IfW2oz\n",
    "\n",
    "Kaggle Contest about cell detection (Data Science Bowl 2018)\n",
    "\n",
    "* https://www.kaggle.com/c/data-science-bowl-2018\n",
    "\n",
    "Particular Kernels of Interest (KoIs)\n",
    "\n",
    "* https://www.kaggle.com/weiji14/yet-another-keras-u-net-data-augmentation\n",
    "* https://www.kaggle.com/piotrczapla/tensorflow-u-net-starter-lb-0-34\n",
    "* https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277?scriptVersionId=2164855\n",
    "\n",
    "Other resources\n",
    "\n",
    "* https://spark-in.me/post/unet-adventures-part-one-getting-acquainted-with-unet\n",
    "* https://towardsdatascience.com/medical-image-segmentation-part-1-unet-convolutional-networks-with-interactive-code-70f0f17f46c6 (Christoph)\n",
    "* https://colab.research.google.com/drive/1BgCDxVdVc0MAe_kC0waMGUV9ShcWW0hM (Christoph)\n",
    "* https://keunwoochoi.wordpress.com/2017/10/11/u-net-on-keras-2-0/ (Jeff)\n",
    "* https://github.com/jocicmarko/ultrasound-nerve-segmentation (Jeff)\n",
    "* https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/ (Gijs)\n",
    "\n",
    "### MOOCs if you have spare time to waste (I havent)\n",
    "http://course.fast.ai/part2.html\n",
    "http://course.fast.ai/lessons/lesson14.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# System\n",
    "from os.path import join, basename, dirname, exists  \n",
    "import os  \n",
    "from glob import glob\n",
    "import csv\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 2201136600 #because Pillow will whine to no end if you feed it big images. You're welcome.\n",
    "\n",
    "\n",
    "# Computational\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from matplotlib import pyplot as plt  \n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Flatten, Dropout, UpSampling2D, core\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Other\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import sklearn\n",
    "from scipy.ndimage import imread  \n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Tracking time\n",
    "This tracks the computation time for the entire notebook. See results in the last cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'ruc0028' # Jeffrey = True\n",
    "#user = 'ruc0030' # Gijs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesius file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/train_images'\n",
    "validation_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/validation_images'\n",
    "test_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/test_images'\n",
    "train_points = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/training_annotations.csv'\n",
    "validation_points = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/validation_annotations.csv' #new\n",
    "data_dir = 'data'\n",
    "train_masks_dir = data_dir+'/train_masks'\n",
    "validation_masks_dir = data_dir+'/validation_masks'\n",
    "results_dir = 'Results'\n",
    "\n",
    "num_channels = 3  #changing this breaks the entire thing but just so you know we include it as an option. \n",
    "\n",
    "gen_patches = False #Whether or not you want to generate new patches. Keep false to use patches stored on disk\n",
    "train_patches_dir = data_dir+'/train_patches'\n",
    "validation_patches_dir = data_dir+'/validation_patches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roi_id</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50811.000000</td>\n",
       "      <td>50811.000000</td>\n",
       "      <td>50811.000000</td>\n",
       "      <td>50811.000000</td>\n",
       "      <td>50811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.810966</td>\n",
       "      <td>0.237240</td>\n",
       "      <td>1896.588442</td>\n",
       "      <td>1407.527356</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.654371</td>\n",
       "      <td>0.026024</td>\n",
       "      <td>1688.602631</td>\n",
       "      <td>1286.433055</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121547</td>\n",
       "      <td>3.398438</td>\n",
       "      <td>4.304688</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>744.808594</td>\n",
       "      <td>574.351562</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>1435.830078</td>\n",
       "      <td>1067.398438</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>2549.500000</td>\n",
       "      <td>1872.800781</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>15101.097656</td>\n",
       "      <td>14209.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             roi_id    pixel_size             x             y   score \n",
       "count  50811.000000  50811.000000  50811.000000  50811.000000  50811.0\n",
       "mean       3.810966      0.237240   1896.588442   1407.527356      1.0\n",
       "std        2.654371      0.026024   1688.602631   1286.433055      0.0\n",
       "min        1.000000      0.121547      3.398438      4.304688      1.0\n",
       "25%        2.000000      0.243094    744.808594    574.351562      1.0\n",
       "50%        3.000000      0.243094   1435.830078   1067.398438      1.0\n",
       "75%        5.000000      0.243094   2549.500000   1872.800781      1.0\n",
       "max       23.000000      0.243094  15101.097656  14209.000000      1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in train csv and show what we've got\n",
    "train_annotations = pd.read_csv(train_points, index_col=False)\n",
    "train_annotations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50811.000000\n",
       "mean         0.237240\n",
       "std          0.026024\n",
       "min          0.121547\n",
       "25%          0.243094\n",
       "50%          0.243094\n",
       "75%          0.243094\n",
       "max          0.243094\n",
       "Name:  pixel_size, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annotations[' pixel_size'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What to gather from this?**\n",
    "\n",
    "We have 50811 points, the pixel sizes vary from 0.12 to 0.24 but the mean is much closer to 0.24 indicating a skewed distribution. Yet, it's good to keep in mind the varying sizes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics on the training data\n",
    "So the annotations file has the locations of each annotated cell. It would be good to know how many lymphocytes per ROI we can expect. The below query produces an ordered list per image and ROI of how many annotations we have per combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roi_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combination_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>T3C02L1A1B1S11R01</td>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>4</td>\n",
       "      <td>T1C02L1A1B1S11R01</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3</td>\n",
       "      <td>35_CD8</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>95-30827-5_CD3</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>37_CD3</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3</td>\n",
       "      <td>T10-4360_I_AG_CD3</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>T2C02L1A1B1S11R01</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>4</td>\n",
       "      <td>12-CD3_27.11.2014_17.27.31</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>T17-071549_III5_CD3</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>6</td>\n",
       "      <td>10_CD8</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 roi_id                    image_id  counts\n",
       "Combination_id                                             \n",
       "33                    1           T3C02L1A1B1S11R01    2052\n",
       "133                   4           T1C02L1A1B1S11R01    1258\n",
       "78                    3                      35_CD8    1045\n",
       "16                    1              95-30827-5_CD3     905\n",
       "9                     1                      37_CD3     842\n",
       "89                    3           T10-4360_I_AG_CD3     804\n",
       "66                    2           T2C02L1A1B1S11R01     799\n",
       "107                   4  12-CD3_27.11.2014_17.27.31     789\n",
       "22                    1         T17-071549_III5_CD3     749\n",
       "169                   6                      10_CD8     736"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get annotations per image, bear in mind this only actually obtains the ROIs that have lymphocytes\n",
    "# note: this specifically returns a dataframe instead of a series so we can plot it with ease\n",
    "df = train_annotations.groupby([' roi_id','image_id']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "df.index.name = 'Combination_id'\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the jupyter server runs locally (Brian, Gijs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttrain_dir = 'train_images'\n",
    "#ttrain_masks_dir = 'train_masks'\n",
    "#train_points = 'training_annotations.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Housekeeping\n",
    "This section defines the convenience methods needed for processing the images.\n",
    "\n",
    "* Creating various masks (used as ground truth)\n",
    "    * Square Masks\n",
    "    * Elipse Masks\n",
    "    * Circular Masks\n",
    "    * Mask creation\n",
    "* Creating patches\n",
    "    * Patch generation\n",
    "* Data augmentation generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    return x.split(', ')\n",
    "\n",
    "def createSquareMask(h, w, center, radius):\n",
    "    mask = np.zeros((h, w), dtype=bool)\n",
    "    lb = center[0] - radius\n",
    "    rb = center[0] + radius\n",
    "    ub = center[1] - radius\n",
    "    bb = center[1] + radius\n",
    "    mask[ub:bb, lb:rb] = True\n",
    "    return mask\n",
    "\n",
    "def createElipseMask(h, w, center, radius):\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + 2*(Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "\n",
    "def createCircularMask(h, w, center, radius):\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "    \n",
    "\n",
    "def createMaskForImage(img_dir, image_path, center_csv, mask_dir, mask_fn):\n",
    "    image_name = image_path.split('.png')[0]\n",
    "    image_id, roi = image_name.split('_ROI_')\n",
    "    print('Processing {}'.format(image_name))\n",
    "    \n",
    "    image = plt.imread(join(img_dir, image_path))\n",
    "    mask = np.zeros((image.shape[0], image.shape[1]))\n",
    "    pixel_size = 0.24309392273426056 # is this the same for each image?\n",
    "     \n",
    "    radius = 2.5 / pixel_size #Brian's was 3.5.\n",
    "    \n",
    "    pois = []\n",
    "    with open(center_csv) as file:\n",
    "        pois = list(map(split, file.readlines()[1:]))\n",
    "    \n",
    "    pois = [poi for poi in pois if (poi[0] == image_id and poi[1] == roi)]\n",
    "\n",
    "    \n",
    "    print('Found {} lymphocytes in this image.'.format(len(pois))) # How many lymps are annotated here?\n",
    "    for poi in pois:\n",
    "        x = int(float(poi[3]))\n",
    "        y = int(float(poi[4]))\n",
    "        shape_mask = mask_fn(image.shape[0], image.shape[1], [x, y], radius)\n",
    "        mask[shape_mask] = 1\n",
    "        \n",
    "    mask_image = Image.fromarray(np.uint8(mask*255), 'L')\n",
    "    mask_image.save(join(mask_dir, image_name + '_mask.png'))\n",
    "    print('Created a mask for: {}'.format(image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 413 training images for patch generation.\n"
     ]
    }
   ],
   "source": [
    "training_paths = os.listdir(train_dir)\n",
    "mask_paths = os.listdir(train_masks_dir)\n",
    "print('Found {} training images for patch generation.'.format(len(training_paths))) # How many images do we actually have?\n",
    "\n",
    "# Go through the masks, print progress because this is a long job!\n",
    "for idx, path in enumerate(training_paths):\n",
    "\n",
    "    mask_name = path.split('.png')[0] + '_mask.png'\n",
    "    if mask_name not in mask_paths:\n",
    "        print('Currently at image {}'.format(idx))\n",
    "        createMaskForImage(train_dir, path, train_points, train_masks_dir, createElipseMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Patch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function generates 1 random patch from patch_amount random images.\n",
    "\n",
    "def generate_patches(img_dir, msk_dir, patch_amount, width, height):\n",
    "    patches = []\n",
    "    all_img_paths = os.listdir(img_dir)\n",
    "    img_paths = random.sample(all_img_paths, patch_amount)\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "        msk_path = img_path.split('.png')[0] + '_mask.png'\n",
    "        img = imread(join(img_dir,img_path))\n",
    "        msk = imread(join(msk_dir, msk_path)) # changed june 1 to include params\n",
    "        msk = np.stack((msk,)*3, 2)\n",
    "\n",
    "        coord = getCoord(img, img_path, width, height, train_points)\n",
    "        if(coord != None):\n",
    "            patch = generate_patch(img,msk,width,height, coord)\n",
    "            patches.append(patch)\n",
    "            print(\"{}: {}  image: {}\".format(len(patches), patch[0].shape, msk_path))\n",
    "            print(\"{}: {}  mask:  {}\".format(len(patches), patch[1].shape, img_path))\n",
    "    while(len(patches) < patch_amount):\n",
    "        print(\"only {} out of {} patches could be generated, recursing now\".format(len(patches), patch_amount))\n",
    "        np.append(patches, generate_patches(img_dir, msk_dir, patch_amount - (len(patches) -1), width, height), axis=0)\n",
    "    return patches\n",
    "\n",
    "#This function generates a single random patch from an image.\n",
    "def generate_patch(img, msk, width, height, coord):\n",
    "    padHeight = 0 if height < img.shape[1] else height-img.shape[1]\n",
    "    padWidth  = 0 if width < img.shape[0] else width-img.shape[0]\n",
    "    if(img.shape[0] < width or img.shape[1] < height):\n",
    "        print(\"padding: {}x{}\".format(padWidth, padHeight))\n",
    "    img = np.pad(img, [(0,padWidth), (0, padHeight), (0,0 )], mode='constant')\n",
    "    msk = np.pad(msk, [(0,padWidth), (0, padHeight), (0,0 )], mode='constant')\n",
    "    #x = random.randint(0,img.shape[0]-width);\n",
    "    x = coord[0]\n",
    "    x1 = x + width\n",
    "    #y = random.randint(0,img.shape[1]-height);\n",
    "    y = coord[1]\n",
    "    y1 = y + height\n",
    "    if x1 > img.shape[0] or y1 > img.shape[1]:\n",
    "        print(\"WARNING x out of bounds ({} > {}) or y out of bounds ({} > {})\".format(x1,img.shape[0],y1,img.shape[1]))\n",
    "    return (np.array(img[x:x1,y:y1,:]), np.array(msk[x:x1,y:y1,:]))\n",
    "\n",
    "patch_log = []\n",
    "coord_tries = []\n",
    "def getCoord(img, img_path, width, height, csv_file):\n",
    "    img_name = img_path.split('.png')[0]\n",
    "    img_id, roi = img_name.split('_ROI_')\n",
    "    pois = []\n",
    "    \n",
    "    with open(csv_file) as file:\n",
    "        pois = list(map(split, file.readlines()[1:]))\n",
    "    pois = [poi for poi in pois if (poi[0] == img_id)]\n",
    "    while(len(coord_tries) < len(pois)):\n",
    "        #for poi in pois:\n",
    "        p = random.randint(0,len(pois)-1)\n",
    "        while(p in coord_tries):\n",
    "            p = random.randint(0,len(pois)-1)\n",
    "        coord_tries.append(p)\n",
    "        poi = pois[p]\n",
    "        x = int(float(poi[3]))\n",
    "        y = int(float(poi[4]))\n",
    "        if( (x,y) in patch_log):\n",
    "            return None\n",
    "        patch_log.append( (x,y) )\n",
    "        if(x - (width/2) >= 0 and x + (width/2) <= img.shape[0] and y - (height/2) >= 0 and y + (height/2) <= img.shape[1]):\n",
    "            return (round(x - (width/2)), round(y - (height/2)))\n",
    "    #poi = pois[np.random.choice(len(pois))]\n",
    "    return (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/sw/python-3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/hpc/sw/python-3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: (512, 512, 3)  image: 4_CD3_ROI_17_mask.png\n",
      "1: (512, 512, 3)  mask:  4_CD3_ROI_17.png\n",
      "2: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_6_mask.png\n",
      "2: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_6.png\n",
      "3: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_2_mask.png\n",
      "3: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_2.png\n",
      "4: (512, 512, 3)  image: T17-071823_III1_CD8_ROI_10_mask.png\n",
      "4: (512, 512, 3)  mask:  T17-071823_III1_CD8_ROI_10.png\n",
      "5: (512, 512, 3)  image: 4_CD3_ROI_13_mask.png\n",
      "5: (512, 512, 3)  mask:  4_CD3_ROI_13.png\n",
      "6: (512, 512, 3)  image: T3C02L1A1B1S11R01_ROI_2_mask.png\n",
      "6: (512, 512, 3)  mask:  T3C02L1A1B1S11R01_ROI_2.png\n",
      "7: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_2_mask.png\n",
      "7: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_2.png\n",
      "8: (512, 512, 3)  image: T17-071841_III6_CD8_ROI_9_mask.png\n",
      "8: (512, 512, 3)  mask:  T17-071841_III6_CD8_ROI_9.png\n",
      "9: (512, 512, 3)  image: 13_CD8_ROI_6_mask.png\n",
      "9: (512, 512, 3)  mask:  13_CD8_ROI_6.png\n",
      "10: (512, 512, 3)  image: 96-08919-4_CD8_ROI_3_mask.png\n",
      "10: (512, 512, 3)  mask:  96-08919-4_CD8_ROI_3.png\n",
      "11: (512, 512, 3)  image: 95-00149-G2_CD3_ROI_8_mask.png\n",
      "11: (512, 512, 3)  mask:  95-00149-G2_CD3_ROI_8.png\n",
      "12: (512, 512, 3)  image: 95-30827-5_CD3_ROI_3_mask.png\n",
      "12: (512, 512, 3)  mask:  95-30827-5_CD3_ROI_3.png\n",
      "13: (512, 512, 3)  image: 4_CD3_ROI_2_mask.png\n",
      "13: (512, 512, 3)  mask:  4_CD3_ROI_2.png\n",
      "14: (512, 512, 3)  image: 96-15186-C_CD3_ROI_9_mask.png\n",
      "14: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_9.png\n",
      "15: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_3_mask.png\n",
      "15: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_3.png\n",
      "16: (512, 512, 3)  image: 28_CD8_ROI_9_mask.png\n",
      "16: (512, 512, 3)  mask:  28_CD8_ROI_9.png\n",
      "17: (512, 512, 3)  image: T1C03L1A2B1S11R01_ROI_7_mask.png\n",
      "17: (512, 512, 3)  mask:  T1C03L1A2B1S11R01_ROI_7.png\n",
      "18: (512, 512, 3)  image: 96-10846-G_CD3_ROI_2_mask.png\n",
      "18: (512, 512, 3)  mask:  96-10846-G_CD3_ROI_2.png\n",
      "19: (512, 512, 3)  image: T17-071825_III7_CD8_ROI_2_mask.png\n",
      "19: (512, 512, 3)  mask:  T17-071825_III7_CD8_ROI_2.png\n",
      "20: (512, 512, 3)  image: T17-071841_III6_CD8_ROI_6_mask.png\n",
      "20: (512, 512, 3)  mask:  T17-071841_III6_CD8_ROI_6.png\n",
      "21: (512, 512, 3)  image: T17-071823_III1_CD8_ROI_8_mask.png\n",
      "21: (512, 512, 3)  mask:  T17-071823_III1_CD8_ROI_8.png\n",
      "22: (512, 512, 3)  image: T2C02L1A1B1S11R01_ROI_4_mask.png\n",
      "22: (512, 512, 3)  mask:  T2C02L1A1B1S11R01_ROI_4.png\n",
      "23: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_15_mask.png\n",
      "23: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_15.png\n",
      "24: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_6_mask.png\n",
      "24: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_6.png\n",
      "25: (512, 512, 3)  image: T17-071825_III4_CD3_ROI_11_mask.png\n",
      "25: (512, 512, 3)  mask:  T17-071825_III4_CD3_ROI_11.png\n",
      "26: (512, 512, 3)  image: 96-08919-4_CD8_ROI_5_mask.png\n",
      "26: (512, 512, 3)  mask:  96-08919-4_CD8_ROI_5.png\n",
      "27: (512, 512, 3)  image: 1080_CD3_ROI_4_mask.png\n",
      "27: (512, 512, 3)  mask:  1080_CD3_ROI_4.png\n",
      "28: (512, 512, 3)  image: T17-071823_III1_CD8_ROI_1_mask.png\n",
      "28: (512, 512, 3)  mask:  T17-071823_III1_CD8_ROI_1.png\n",
      "29: (512, 512, 3)  image: 1080_CD3_ROI_7_mask.png\n",
      "29: (512, 512, 3)  mask:  1080_CD3_ROI_7.png\n",
      "30: (512, 512, 3)  image: 28_CD8_ROI_14_mask.png\n",
      "30: (512, 512, 3)  mask:  28_CD8_ROI_14.png\n",
      "31: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_3_mask.png\n",
      "31: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_3.png\n",
      "32: (512, 512, 3)  image: 4_CD3_ROI_14_mask.png\n",
      "32: (512, 512, 3)  mask:  4_CD3_ROI_14.png\n",
      "33: (512, 512, 3)  image: 3_CD8_ROI_14_mask.png\n",
      "33: (512, 512, 3)  mask:  3_CD8_ROI_14.png\n",
      "34: (512, 512, 3)  image: T17-071823_III3_CD8_ROI_10_mask.png\n",
      "34: (512, 512, 3)  mask:  T17-071823_III3_CD8_ROI_10.png\n",
      "35: (512, 512, 3)  image: 28_CD8_ROI_13_mask.png\n",
      "35: (512, 512, 3)  mask:  28_CD8_ROI_13.png\n",
      "36: (512, 512, 3)  image: T17-071549_III3_CD3_ROI_3_mask.png\n",
      "36: (512, 512, 3)  mask:  T17-071549_III3_CD3_ROI_3.png\n",
      "37: (512, 512, 3)  image: T17-071827_III2_CD-3_ROI_1_mask.png\n",
      "37: (512, 512, 3)  mask:  T17-071827_III2_CD-3_ROI_1.png\n",
      "38: (512, 512, 3)  image: T3C03L1A2B1S11R01_ROI_5_mask.png\n",
      "38: (512, 512, 3)  mask:  T3C03L1A2B1S11R01_ROI_5.png\n",
      "39: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_10_mask.png\n",
      "39: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_10.png\n",
      "40: (512, 512, 3)  image: T1C02L1A1B1S11R01_ROI_2_mask.png\n",
      "40: (512, 512, 3)  mask:  T1C02L1A1B1S11R01_ROI_2.png\n",
      "41: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_3_mask.png\n",
      "41: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_3.png\n",
      "42: (512, 512, 3)  image: T3C03L1A2B1S11R01_ROI_3_mask.png\n",
      "42: (512, 512, 3)  mask:  T3C03L1A2B1S11R01_ROI_3.png\n",
      "43: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_7_mask.png\n",
      "43: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_7.png\n",
      "44: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_4_mask.png\n",
      "44: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_4.png\n",
      "45: (512, 512, 3)  image: 4_CD3_ROI_9_mask.png\n",
      "45: (512, 512, 3)  mask:  4_CD3_ROI_9.png\n",
      "46: (512, 512, 3)  image: T17-071841_III6_CD8_ROI_3_mask.png\n",
      "46: (512, 512, 3)  mask:  T17-071841_III6_CD8_ROI_3.png\n",
      "47: (512, 512, 3)  image: 3_CD8_ROI_3_mask.png\n",
      "47: (512, 512, 3)  mask:  3_CD8_ROI_3.png\n",
      "48: (512, 512, 3)  image: T17-071549_III3_CD3_ROI_11_mask.png\n",
      "48: (512, 512, 3)  mask:  T17-071549_III3_CD3_ROI_11.png\n",
      "49: (512, 512, 3)  image: T10-4360_I_Y_CD8_ROI_4_mask.png\n",
      "49: (512, 512, 3)  mask:  T10-4360_I_Y_CD8_ROI_4.png\n",
      "50: (512, 512, 3)  image: T1C03L1A2B1S11R01_ROI_3_mask.png\n",
      "50: (512, 512, 3)  mask:  T1C03L1A2B1S11R01_ROI_3.png\n",
      "51: (512, 512, 3)  image: T1C02L1A1B1S11R01_ROI_5_mask.png\n",
      "51: (512, 512, 3)  mask:  T1C02L1A1B1S11R01_ROI_5.png\n",
      "52: (512, 512, 3)  image: T17-071823_III3_CD8_ROI_3_mask.png\n",
      "52: (512, 512, 3)  mask:  T17-071823_III3_CD8_ROI_3.png\n",
      "padding: 131x0\n",
      "53: (512, 512, 3)  image: 19-CD3_ROI_23_mask.png\n",
      "53: (512, 512, 3)  mask:  19-CD3_ROI_23.png\n",
      "54: (512, 512, 3)  image: T1C03L1A2B1S11R01_ROI_1_mask.png\n",
      "54: (512, 512, 3)  mask:  T1C03L1A2B1S11R01_ROI_1.png\n",
      "55: (512, 512, 3)  image: T3C02L1A1B1S11R01_ROI_3_mask.png\n",
      "55: (512, 512, 3)  mask:  T3C02L1A1B1S11R01_ROI_3.png\n",
      "56: (512, 512, 3)  image: 10_CD8_ROI_4_mask.png\n",
      "56: (512, 512, 3)  mask:  10_CD8_ROI_4.png\n",
      "padding: 72x0\n",
      "57: (512, 512, 3)  image: 19-CD3_ROI_19_mask.png\n",
      "57: (512, 512, 3)  mask:  19-CD3_ROI_19.png\n",
      "58: (512, 512, 3)  image: 35_CD8_ROI_1_mask.png\n",
      "58: (512, 512, 3)  mask:  35_CD8_ROI_1.png\n",
      "59: (512, 512, 3)  image: 35_CD8_ROI_4_mask.png\n",
      "59: (512, 512, 3)  mask:  35_CD8_ROI_4.png\n",
      "60: (512, 512, 3)  image: T1C03L1A2B1S11R01_ROI_10_mask.png\n",
      "60: (512, 512, 3)  mask:  T1C03L1A2B1S11R01_ROI_10.png\n",
      "61: (512, 512, 3)  image: 4_CD3_ROI_6_mask.png\n",
      "61: (512, 512, 3)  mask:  4_CD3_ROI_6.png\n",
      "62: (512, 512, 3)  image: T10-4360_I_Y_CD8_ROI_8_mask.png\n",
      "62: (512, 512, 3)  mask:  T10-4360_I_Y_CD8_ROI_8.png\n",
      "63: (512, 512, 3)  image: T17-071549_III3_CD3_ROI_4_mask.png\n",
      "63: (512, 512, 3)  mask:  T17-071549_III3_CD3_ROI_4.png\n",
      "padding: 188x49\n",
      "64: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_17_mask.png\n",
      "64: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_17.png\n",
      "65: (512, 512, 3)  image: 96-08919-4_CD8_ROI_2_mask.png\n",
      "65: (512, 512, 3)  mask:  96-08919-4_CD8_ROI_2.png\n",
      "66: (512, 512, 3)  image: 13_CD8_ROI_5_mask.png\n",
      "66: (512, 512, 3)  mask:  13_CD8_ROI_5.png\n",
      "67: (512, 512, 3)  image: T17-071549_III3_CD3_ROI_8_mask.png\n",
      "67: (512, 512, 3)  mask:  T17-071549_III3_CD3_ROI_8.png\n",
      "68: (512, 512, 3)  image: 28_CD8_ROI_12_mask.png\n",
      "68: (512, 512, 3)  mask:  28_CD8_ROI_12.png\n",
      "69: (512, 512, 3)  image: 35_CD8_ROI_2_mask.png\n",
      "69: (512, 512, 3)  mask:  35_CD8_ROI_2.png\n",
      "70: (512, 512, 3)  image: T10-4360_I_Y_CD8_ROI_7_mask.png\n",
      "70: (512, 512, 3)  mask:  T10-4360_I_Y_CD8_ROI_7.png\n",
      "71: (512, 512, 3)  image: 19-CD3_ROI_16_mask.png\n",
      "71: (512, 512, 3)  mask:  19-CD3_ROI_16.png\n",
      "72: (512, 512, 3)  image: T1C02L1A1B1S11R01_ROI_4_mask.png\n",
      "72: (512, 512, 3)  mask:  T1C02L1A1B1S11R01_ROI_4.png\n",
      "73: (512, 512, 3)  image: 10_CD8_ROI_1_mask.png\n",
      "73: (512, 512, 3)  mask:  10_CD8_ROI_1.png\n",
      "74: (512, 512, 3)  image: 4_CD3_ROI_18_mask.png\n",
      "74: (512, 512, 3)  mask:  4_CD3_ROI_18.png\n",
      "75: (512, 512, 3)  image: 19-CD3_ROI_18_mask.png\n",
      "75: (512, 512, 3)  mask:  19-CD3_ROI_18.png\n",
      "76: (512, 512, 3)  image: 95-00149-G2_CD3_ROI_7_mask.png\n",
      "76: (512, 512, 3)  mask:  95-00149-G2_CD3_ROI_7.png\n",
      "77: (512, 512, 3)  image: 95-22625-I-4_CD8_ROI_3_mask.png\n",
      "77: (512, 512, 3)  mask:  95-22625-I-4_CD8_ROI_3.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_7_mask.png\n",
      "78: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_7.png\n",
      "79: (512, 512, 3)  image: 96-15186-C_CD3_ROI_4_mask.png\n",
      "79: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_4.png\n",
      "80: (512, 512, 3)  image: 10_CD8_ROI_3_mask.png\n",
      "80: (512, 512, 3)  mask:  10_CD8_ROI_3.png\n",
      "81: (512, 512, 3)  image: 96-10846-G_CD3_ROI_1_mask.png\n",
      "81: (512, 512, 3)  mask:  96-10846-G_CD3_ROI_1.png\n",
      "82: (512, 512, 3)  image: 31_CD3_ROI_12_mask.png\n",
      "82: (512, 512, 3)  mask:  31_CD3_ROI_12.png\n",
      "83: (512, 512, 3)  image: 3_CD8_ROI_10_mask.png\n",
      "83: (512, 512, 3)  mask:  3_CD8_ROI_10.png\n",
      "84: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_7_mask.png\n",
      "84: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_7.png\n",
      "85: (512, 512, 3)  image: 37_CD3_ROI_2_mask.png\n",
      "85: (512, 512, 3)  mask:  37_CD3_ROI_2.png\n",
      "padding: 102x0\n",
      "86: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_6_mask.png\n",
      "86: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_6.png\n",
      "87: (512, 512, 3)  image: 19-CD3_ROI_5_mask.png\n",
      "87: (512, 512, 3)  mask:  19-CD3_ROI_5.png\n",
      "88: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_2_mask.png\n",
      "88: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_2.png\n",
      "89: (512, 512, 3)  image: T17-071841_III6_CD8_ROI_4_mask.png\n",
      "89: (512, 512, 3)  mask:  T17-071841_III6_CD8_ROI_4.png\n",
      "90: (512, 512, 3)  image: 96-08919-4_CD8_ROI_4_mask.png\n",
      "90: (512, 512, 3)  mask:  96-08919-4_CD8_ROI_4.png\n",
      "91: (512, 512, 3)  image: T10-4360_I_Y_CD8_ROI_5_mask.png\n",
      "91: (512, 512, 3)  mask:  T10-4360_I_Y_CD8_ROI_5.png\n",
      "92: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_10_mask.png\n",
      "92: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_10.png\n",
      "93: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_8_mask.png\n",
      "93: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_8.png\n",
      "94: (512, 512, 3)  image: T3C02L1A1B1S11R01_ROI_6_mask.png\n",
      "94: (512, 512, 3)  mask:  T3C02L1A1B1S11R01_ROI_6.png\n",
      "95: (512, 512, 3)  image: T17-071549_III3_CD3_ROI_10_mask.png\n",
      "95: (512, 512, 3)  mask:  T17-071549_III3_CD3_ROI_10.png\n",
      "96: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_13_mask.png\n",
      "96: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_13.png\n",
      "97: (512, 512, 3)  image: 28_CD8_ROI_8_mask.png\n",
      "97: (512, 512, 3)  mask:  28_CD8_ROI_8.png\n",
      "98: (512, 512, 3)  image: 10_CD8_ROI_2_mask.png\n",
      "98: (512, 512, 3)  mask:  10_CD8_ROI_2.png\n",
      "99: (512, 512, 3)  image: 95-00149-G2_CD3_ROI_1_mask.png\n",
      "99: (512, 512, 3)  mask:  95-00149-G2_CD3_ROI_1.png\n",
      "100: (512, 512, 3)  image: 95-00149-G2_CD3_ROI_6_mask.png\n",
      "100: (512, 512, 3)  mask:  95-00149-G2_CD3_ROI_6.png\n",
      "101: (512, 512, 3)  image: T17-071823_III3_CD8_ROI_2_mask.png\n",
      "101: (512, 512, 3)  mask:  T17-071823_III3_CD8_ROI_2.png\n",
      "102: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_1_mask.png\n",
      "102: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_1.png\n",
      "103: (512, 512, 3)  image: 96-15186-C_CD3_ROI_13_mask.png\n",
      "103: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_13.png\n",
      "104: (512, 512, 3)  image: T17-071825_III4_CD3_ROI_9_mask.png\n",
      "104: (512, 512, 3)  mask:  T17-071825_III4_CD3_ROI_9.png\n",
      "105: (512, 512, 3)  image: 19-CD3_ROI_14_mask.png\n",
      "105: (512, 512, 3)  mask:  19-CD3_ROI_14.png\n",
      "106: (512, 512, 3)  image: T17-071823_III3_CD8_ROI_4_mask.png\n",
      "106: (512, 512, 3)  mask:  T17-071823_III3_CD8_ROI_4.png\n",
      "107: (512, 512, 3)  image: 37_CD3_ROI_3_mask.png\n",
      "107: (512, 512, 3)  mask:  37_CD3_ROI_3.png\n",
      "108: (512, 512, 3)  image: T17-071825_III7_CD8_ROI_8_mask.png\n",
      "108: (512, 512, 3)  mask:  T17-071825_III7_CD8_ROI_8.png\n",
      "109: (512, 512, 3)  image: T17-071827_III2_CD-3_ROI_2_mask.png\n",
      "109: (512, 512, 3)  mask:  T17-071827_III2_CD-3_ROI_2.png\n",
      "110: (512, 512, 3)  image: 95-22625-I-4_CD8_ROI_1_mask.png\n",
      "110: (512, 512, 3)  mask:  95-22625-I-4_CD8_ROI_1.png\n",
      "111: (512, 512, 3)  image: T17-071823_III1_CD8_ROI_2_mask.png\n",
      "111: (512, 512, 3)  mask:  T17-071823_III1_CD8_ROI_2.png\n",
      "112: (512, 512, 3)  image: T17-071841_III6_CD8_ROI_8_mask.png\n",
      "112: (512, 512, 3)  mask:  T17-071841_III6_CD8_ROI_8.png\n",
      "113: (512, 512, 3)  image: 95-30827-5_CD3_ROI_5_mask.png\n",
      "113: (512, 512, 3)  mask:  95-30827-5_CD3_ROI_5.png\n",
      "114: (512, 512, 3)  image: T17-071825_III4_CD3_ROI_8_mask.png\n",
      "114: (512, 512, 3)  mask:  T17-071825_III4_CD3_ROI_8.png\n",
      "115: (512, 512, 3)  image: T17-071825_III7_CD8_ROI_1_mask.png\n",
      "115: (512, 512, 3)  mask:  T17-071825_III7_CD8_ROI_1.png\n",
      "116: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_7_mask.png\n",
      "116: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_7.png\n",
      "117: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_3_mask.png\n",
      "117: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_3.png\n",
      "118: (512, 512, 3)  image: T17-071825_III4_CD3_ROI_4_mask.png\n",
      "118: (512, 512, 3)  mask:  T17-071825_III4_CD3_ROI_4.png\n",
      "padding: 32x0\n",
      "119: (512, 512, 3)  image: T3C02L1A1B1S11R01_ROI_7_mask.png\n",
      "119: (512, 512, 3)  mask:  T3C02L1A1B1S11R01_ROI_7.png\n",
      "120: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_1_mask.png\n",
      "120: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_1.png\n",
      "121: (512, 512, 3)  image: T3C03L1A2B1S11R01_ROI_1_mask.png\n",
      "121: (512, 512, 3)  mask:  T3C03L1A2B1S11R01_ROI_1.png\n",
      "122: (512, 512, 3)  image: 28_CD8_ROI_5_mask.png\n",
      "122: (512, 512, 3)  mask:  28_CD8_ROI_5.png\n",
      "123: (512, 512, 3)  image: T17-071825_III4_CD3_ROI_10_mask.png\n",
      "123: (512, 512, 3)  mask:  T17-071825_III4_CD3_ROI_10.png\n",
      "124: (512, 512, 3)  image: 95-30827-5_CD3_ROI_9_mask.png\n",
      "124: (512, 512, 3)  mask:  95-30827-5_CD3_ROI_9.png\n",
      "125: (512, 512, 3)  image: 13_CD8_ROI_1_mask.png\n",
      "125: (512, 512, 3)  mask:  13_CD8_ROI_1.png\n",
      "126: (512, 512, 3)  image: 96-15186-C_CD3_ROI_1_mask.png\n",
      "126: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_1.png\n",
      "127: (512, 512, 3)  image: 13_CD8_ROI_3_mask.png\n",
      "127: (512, 512, 3)  mask:  13_CD8_ROI_3.png\n",
      "128: (512, 512, 3)  image: 95-22625-I-4_CD8_ROI_4_mask.png\n",
      "128: (512, 512, 3)  mask:  95-22625-I-4_CD8_ROI_4.png\n",
      "129: (512, 512, 3)  image: T17-071825_III7_CD8_ROI_9_mask.png\n",
      "129: (512, 512, 3)  mask:  T17-071825_III7_CD8_ROI_9.png\n",
      "padding: 89x17\n",
      "130: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_10_mask.png\n",
      "130: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_10.png\n",
      "131: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_9_mask.png\n",
      "131: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_9.png\n",
      "132: (512, 512, 3)  image: 2-CD3_ROI_2_mask.png\n",
      "132: (512, 512, 3)  mask:  2-CD3_ROI_2.png\n",
      "133: (512, 512, 3)  image: 1002_CD3_ROI_2_mask.png\n",
      "133: (512, 512, 3)  mask:  1002_CD3_ROI_2.png\n",
      "134: (512, 512, 3)  image: 19-CD3_ROI_8_mask.png\n",
      "134: (512, 512, 3)  mask:  19-CD3_ROI_8.png\n",
      "135: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_11_mask.png\n",
      "135: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_11.png\n",
      "136: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_6_mask.png\n",
      "136: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_6.png\n",
      "padding: 31x0\n",
      "137: (512, 512, 3)  image: 13_CD8_ROI_14_mask.png\n",
      "137: (512, 512, 3)  mask:  13_CD8_ROI_14.png\n",
      "138: (512, 512, 3)  image: T17-071823_III3_CD8_ROI_5_mask.png\n",
      "138: (512, 512, 3)  mask:  T17-071823_III3_CD8_ROI_5.png\n",
      "139: (512, 512, 3)  image: 28_CD8_ROI_1_mask.png\n",
      "139: (512, 512, 3)  mask:  28_CD8_ROI_1.png\n",
      "140: (512, 512, 3)  image: 10_CD8_ROI_10_mask.png\n",
      "140: (512, 512, 3)  mask:  10_CD8_ROI_10.png\n",
      "141: (512, 512, 3)  image: T17-071825_III7_CD8_ROI_3_mask.png\n",
      "141: (512, 512, 3)  mask:  T17-071825_III7_CD8_ROI_3.png\n",
      "142: (512, 512, 3)  image: T1C03L1A2B1S11R01_ROI_5_mask.png\n",
      "142: (512, 512, 3)  mask:  T1C03L1A2B1S11R01_ROI_5.png\n",
      "143: (512, 512, 3)  image: 13_CD8_ROI_7_mask.png\n",
      "143: (512, 512, 3)  mask:  13_CD8_ROI_7.png\n",
      "144: (512, 512, 3)  image: T3C02L1A1B1S11R01_ROI_1_mask.png\n",
      "144: (512, 512, 3)  mask:  T3C02L1A1B1S11R01_ROI_1.png\n",
      "145: (512, 512, 3)  image: T17-071825_III4_CD3_ROI_3_mask.png\n",
      "145: (512, 512, 3)  mask:  T17-071825_III4_CD3_ROI_3.png\n",
      "146: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_13_mask.png\n",
      "146: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_13.png\n",
      "147: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_5_mask.png\n",
      "147: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_5.png\n",
      "148: (512, 512, 3)  image: T17-071841_III6_CD8_ROI_5_mask.png\n",
      "148: (512, 512, 3)  mask:  T17-071841_III6_CD8_ROI_5.png\n",
      "149: (512, 512, 3)  image: T17-071823_III3_CD8_ROI_6_mask.png\n",
      "149: (512, 512, 3)  mask:  T17-071823_III3_CD8_ROI_6.png\n",
      "150: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_4_mask.png\n",
      "150: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_4.png\n",
      "151: (512, 512, 3)  image: 96-10846-G_CD3_ROI_5_mask.png\n",
      "151: (512, 512, 3)  mask:  96-10846-G_CD3_ROI_5.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152: (512, 512, 3)  image: 31_CD3_ROI_6_mask.png\n",
      "152: (512, 512, 3)  mask:  31_CD3_ROI_6.png\n",
      "153: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_15_mask.png\n",
      "153: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_15.png\n",
      "154: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_10_mask.png\n",
      "154: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_10.png\n",
      "padding: 10x0\n",
      "155: (512, 512, 3)  image: 19-CD3_ROI_4_mask.png\n",
      "155: (512, 512, 3)  mask:  19-CD3_ROI_4.png\n",
      "156: (512, 512, 3)  image: T2C02L1A1B1S11R01_ROI_7_mask.png\n",
      "156: (512, 512, 3)  mask:  T2C02L1A1B1S11R01_ROI_7.png\n",
      "157: (512, 512, 3)  image: 35_CD8_ROI_3_mask.png\n",
      "157: (512, 512, 3)  mask:  35_CD8_ROI_3.png\n",
      "padding: 178x0\n",
      "158: (512, 512, 3)  image: 1080_CD3_ROI_8_mask.png\n",
      "158: (512, 512, 3)  mask:  1080_CD3_ROI_8.png\n",
      "159: (512, 512, 3)  image: 2-CD3_ROI_1_mask.png\n",
      "159: (512, 512, 3)  mask:  2-CD3_ROI_1.png\n",
      "160: (512, 512, 3)  image: T1C02L1A1B1S11R01_ROI_1_mask.png\n",
      "160: (512, 512, 3)  mask:  T1C02L1A1B1S11R01_ROI_1.png\n",
      "161: (512, 512, 3)  image: 95-22625-I-4_CD8_ROI_6_mask.png\n",
      "161: (512, 512, 3)  mask:  95-22625-I-4_CD8_ROI_6.png\n",
      "162: (512, 512, 3)  image: T10-4360_I_Y_CD8_ROI_1_mask.png\n",
      "162: (512, 512, 3)  mask:  T10-4360_I_Y_CD8_ROI_1.png\n",
      "163: (512, 512, 3)  image: T17-071825_III7_CD8_ROI_6_mask.png\n",
      "163: (512, 512, 3)  mask:  T17-071825_III7_CD8_ROI_6.png\n",
      "164: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_5_mask.png\n",
      "164: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_5.png\n",
      "165: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_5_mask.png\n",
      "165: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_5.png\n",
      "166: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_12_mask.png\n",
      "166: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_12.png\n",
      "167: (512, 512, 3)  image: 37_CD3_ROI_1_mask.png\n",
      "167: (512, 512, 3)  mask:  37_CD3_ROI_1.png\n",
      "168: (512, 512, 3)  image: T10-4360_I_Y_CD8_ROI_2_mask.png\n",
      "168: (512, 512, 3)  mask:  T10-4360_I_Y_CD8_ROI_2.png\n",
      "169: (512, 512, 3)  image: 4_CD3_ROI_3_mask.png\n",
      "169: (512, 512, 3)  mask:  4_CD3_ROI_3.png\n",
      "170: (512, 512, 3)  image: 31_CD3_ROI_14_mask.png\n",
      "170: (512, 512, 3)  mask:  31_CD3_ROI_14.png\n",
      "171: (512, 512, 3)  image: T2C02L1A1B1S11R01_ROI_2_mask.png\n",
      "171: (512, 512, 3)  mask:  T2C02L1A1B1S11R01_ROI_2.png\n",
      "172: (512, 512, 3)  image: T1C02L1A1B1S11R01_ROI_3_mask.png\n",
      "172: (512, 512, 3)  mask:  T1C02L1A1B1S11R01_ROI_3.png\n",
      "173: (512, 512, 3)  image: T1C03L1A2B1S11R01_ROI_4_mask.png\n",
      "173: (512, 512, 3)  mask:  T1C03L1A2B1S11R01_ROI_4.png\n",
      "174: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_2_mask.png\n",
      "174: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_2.png\n",
      "175: (512, 512, 3)  image: 4_CD3_ROI_8_mask.png\n",
      "175: (512, 512, 3)  mask:  4_CD3_ROI_8.png\n",
      "176: (512, 512, 3)  image: 1002_CD3_ROI_3_mask.png\n",
      "176: (512, 512, 3)  mask:  1002_CD3_ROI_3.png\n",
      "177: (512, 512, 3)  image: 96-15186-C_CD3_ROI_11_mask.png\n",
      "177: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_11.png\n",
      "178: (512, 512, 3)  image: 31_CD3_ROI_7_mask.png\n",
      "178: (512, 512, 3)  mask:  31_CD3_ROI_7.png\n",
      "179: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_11_mask.png\n",
      "179: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_11.png\n",
      "180: (512, 512, 3)  image: 95-22625-I-4_CD8_ROI_8_mask.png\n",
      "180: (512, 512, 3)  mask:  95-22625-I-4_CD8_ROI_8.png\n",
      "181: (512, 512, 3)  image: T1C02L1A1B1S11R01_ROI_6_mask.png\n",
      "181: (512, 512, 3)  mask:  T1C02L1A1B1S11R01_ROI_6.png\n",
      "182: (512, 512, 3)  image: 13_CD8_ROI_2_mask.png\n",
      "182: (512, 512, 3)  mask:  13_CD8_ROI_2.png\n",
      "183: (512, 512, 3)  image: 10_CD8_ROI_9_mask.png\n",
      "183: (512, 512, 3)  mask:  10_CD8_ROI_9.png\n",
      "184: (512, 512, 3)  image: 3_CD8_ROI_11_mask.png\n",
      "184: (512, 512, 3)  mask:  3_CD8_ROI_11.png\n",
      "185: (512, 512, 3)  image: T17-071823_III1_CD8_ROI_7_mask.png\n",
      "185: (512, 512, 3)  mask:  T17-071823_III1_CD8_ROI_7.png\n",
      "186: (512, 512, 3)  image: T17-071827_III2_CD-3_ROI_4_mask.png\n",
      "186: (512, 512, 3)  mask:  T17-071827_III2_CD-3_ROI_4.png\n",
      "187: (512, 512, 3)  image: 4_CD3_ROI_7_mask.png\n",
      "187: (512, 512, 3)  mask:  4_CD3_ROI_7.png\n",
      "188: (512, 512, 3)  image: T17-071841_III6_CD8_ROI_1_mask.png\n",
      "188: (512, 512, 3)  mask:  T17-071841_III6_CD8_ROI_1.png\n",
      "189: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_7_mask.png\n",
      "189: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_7.png\n",
      "padding: 156x107\n",
      "190: (512, 512, 3)  image: 13_CD8_ROI_13_mask.png\n",
      "190: (512, 512, 3)  mask:  13_CD8_ROI_13.png\n",
      "padding: 209x108\n",
      "191: (512, 512, 3)  image: 19-CD3_ROI_10_mask.png\n",
      "191: (512, 512, 3)  mask:  19-CD3_ROI_10.png\n",
      "192: (512, 512, 3)  image: 96-15186-C_CD3_ROI_14_mask.png\n",
      "192: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_14.png\n",
      "padding: 79x0\n",
      "193: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_10_mask.png\n",
      "193: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_10.png\n",
      "194: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_12_mask.png\n",
      "194: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_12.png\n",
      "195: (512, 512, 3)  image: 1080_CD3_ROI_5_mask.png\n",
      "195: (512, 512, 3)  mask:  1080_CD3_ROI_5.png\n",
      "196: (512, 512, 3)  image: 96-15186-C_CD3_ROI_3_mask.png\n",
      "196: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_3.png\n",
      "padding: 36x94\n",
      "197: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_18_mask.png\n",
      "197: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_18.png\n",
      "198: (512, 512, 3)  image: T17-071827_III2_CD-3_ROI_9_mask.png\n",
      "198: (512, 512, 3)  mask:  T17-071827_III2_CD-3_ROI_9.png\n",
      "199: (512, 512, 3)  image: 13_CD8_ROI_8_mask.png\n",
      "199: (512, 512, 3)  mask:  13_CD8_ROI_8.png\n",
      "200: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_2_mask.png\n",
      "200: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_2.png\n",
      "201: (512, 512, 3)  image: T3C02L1A1B1S11R01_ROI_4_mask.png\n",
      "201: (512, 512, 3)  mask:  T3C02L1A1B1S11R01_ROI_4.png\n",
      "202: (512, 512, 3)  image: T17-071827_III2_CD-3_ROI_3_mask.png\n",
      "202: (512, 512, 3)  mask:  T17-071827_III2_CD-3_ROI_3.png\n",
      "203: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_6_mask.png\n",
      "203: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_6.png\n",
      "204: (512, 512, 3)  image: T17-071825_III4_CD3_ROI_7_mask.png\n",
      "204: (512, 512, 3)  mask:  T17-071825_III4_CD3_ROI_7.png\n",
      "205: (512, 512, 3)  image: 13_CD8_ROI_4_mask.png\n",
      "205: (512, 512, 3)  mask:  13_CD8_ROI_4.png\n",
      "206: (512, 512, 3)  image: 35_CD8_ROI_6_mask.png\n",
      "206: (512, 512, 3)  mask:  35_CD8_ROI_6.png\n",
      "207: (512, 512, 3)  image: 95-00149-G2_CD3_ROI_2_mask.png\n",
      "207: (512, 512, 3)  mask:  95-00149-G2_CD3_ROI_2.png\n",
      "208: (512, 512, 3)  image: 13_CD8_ROI_9_mask.png\n",
      "208: (512, 512, 3)  mask:  13_CD8_ROI_9.png\n",
      "209: (512, 512, 3)  image: 95-22625-I-4_CD8_ROI_7_mask.png\n",
      "209: (512, 512, 3)  mask:  95-22625-I-4_CD8_ROI_7.png\n",
      "210: (512, 512, 3)  image: 31_CD3_ROI_5_mask.png\n",
      "210: (512, 512, 3)  mask:  31_CD3_ROI_5.png\n",
      "211: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_13_mask.png\n",
      "211: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_13.png\n",
      "212: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_12_mask.png\n",
      "212: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_12.png\n",
      "213: (512, 512, 3)  image: 95-22625-I-4_CD8_ROI_2_mask.png\n",
      "213: (512, 512, 3)  mask:  95-22625-I-4_CD8_ROI_2.png\n",
      "padding: 122x0\n",
      "214: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_11_mask.png\n",
      "214: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_11.png\n",
      "215: (512, 512, 3)  image: 31_CD3_ROI_4_mask.png\n",
      "215: (512, 512, 3)  mask:  31_CD3_ROI_4.png\n",
      "padding: 1x0\n",
      "216: (512, 512, 3)  image: 2-CD3_ROI_7_mask.png\n",
      "216: (512, 512, 3)  mask:  2-CD3_ROI_7.png\n",
      "217: (512, 512, 3)  image: T17-071823_III1_CD8_ROI_4_mask.png\n",
      "217: (512, 512, 3)  mask:  T17-071823_III1_CD8_ROI_4.png\n",
      "218: (512, 512, 3)  image: T17-071823_III1_CD8_ROI_5_mask.png\n",
      "218: (512, 512, 3)  mask:  T17-071823_III1_CD8_ROI_5.png\n",
      "219: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_14_mask.png\n",
      "219: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_14.png\n",
      "padding: 160x116\n",
      "220: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_9_mask.png\n",
      "220: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_9.png\n",
      "221: (512, 512, 3)  image: T3C03L1A2B1S11R01_ROI_4_mask.png\n",
      "221: (512, 512, 3)  mask:  T3C03L1A2B1S11R01_ROI_4.png\n",
      "222: (512, 512, 3)  image: T1C02L1A1B1S11R01_ROI_8_mask.png\n",
      "222: (512, 512, 3)  mask:  T1C02L1A1B1S11R01_ROI_8.png\n",
      "223: (512, 512, 3)  image: T1C03L1A2B1S11R01_ROI_6_mask.png\n",
      "223: (512, 512, 3)  mask:  T1C03L1A2B1S11R01_ROI_6.png\n",
      "224: (512, 512, 3)  image: 2-CD3_ROI_5_mask.png\n",
      "224: (512, 512, 3)  mask:  2-CD3_ROI_5.png\n",
      "225: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_1_mask.png\n",
      "225: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_1.png\n",
      "226: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_4_mask.png\n",
      "226: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_4.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227: (512, 512, 3)  image: 19-CD3_ROI_7_mask.png\n",
      "227: (512, 512, 3)  mask:  19-CD3_ROI_7.png\n",
      "228: (512, 512, 3)  image: T17-071825_III4_CD3_ROI_6_mask.png\n",
      "228: (512, 512, 3)  mask:  T17-071825_III4_CD3_ROI_6.png\n",
      "229: (512, 512, 3)  image: 96-10846-G_CD3_ROI_4_mask.png\n",
      "229: (512, 512, 3)  mask:  96-10846-G_CD3_ROI_4.png\n",
      "230: (512, 512, 3)  image: 95-30827-5_CD3_ROI_12_mask.png\n",
      "230: (512, 512, 3)  mask:  95-30827-5_CD3_ROI_12.png\n",
      "231: (512, 512, 3)  image: 95-00149-G2_CD3_ROI_3_mask.png\n",
      "231: (512, 512, 3)  mask:  95-00149-G2_CD3_ROI_3.png\n",
      "232: (512, 512, 3)  image: T10-4360_I_Y_CD8_ROI_6_mask.png\n",
      "232: (512, 512, 3)  mask:  T10-4360_I_Y_CD8_ROI_6.png\n",
      "233: (512, 512, 3)  image: T10-4360_I_Y_CD8_ROI_9_mask.png\n",
      "233: (512, 512, 3)  mask:  T10-4360_I_Y_CD8_ROI_9.png\n",
      "234: (512, 512, 3)  image: 4_CD3_ROI_1_mask.png\n",
      "234: (512, 512, 3)  mask:  4_CD3_ROI_1.png\n",
      "235: (512, 512, 3)  image: 2-CD3_ROI_10_mask.png\n",
      "235: (512, 512, 3)  mask:  2-CD3_ROI_10.png\n",
      "236: (512, 512, 3)  image: 31_CD3_ROI_2_mask.png\n",
      "236: (512, 512, 3)  mask:  31_CD3_ROI_2.png\n",
      "237: (512, 512, 3)  image: 28_CD8_ROI_2_mask.png\n",
      "237: (512, 512, 3)  mask:  28_CD8_ROI_2.png\n",
      "238: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_1_mask.png\n",
      "238: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_1.png\n",
      "padding: 234x81\n",
      "239: (512, 512, 3)  image: 19-CD3_ROI_13_mask.png\n",
      "239: (512, 512, 3)  mask:  19-CD3_ROI_13.png\n",
      "240: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_10_mask.png\n",
      "240: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_10.png\n",
      "241: (512, 512, 3)  image: 10_CD8_ROI_6_mask.png\n",
      "241: (512, 512, 3)  mask:  10_CD8_ROI_6.png\n",
      "242: (512, 512, 3)  image: T17-071827_III2_CD-3_ROI_6_mask.png\n",
      "242: (512, 512, 3)  mask:  T17-071827_III2_CD-3_ROI_6.png\n",
      "243: (512, 512, 3)  image: T3C03L1A2B1S11R01_ROI_6_mask.png\n",
      "243: (512, 512, 3)  mask:  T3C03L1A2B1S11R01_ROI_6.png\n",
      "244: (512, 512, 3)  image: 95-00149-G2_CD3_ROI_4_mask.png\n",
      "244: (512, 512, 3)  mask:  95-00149-G2_CD3_ROI_4.png\n",
      "245: (512, 512, 3)  image: T17-071823_III3_CD8_ROI_8_mask.png\n",
      "245: (512, 512, 3)  mask:  T17-071823_III3_CD8_ROI_8.png\n",
      "246: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_16_mask.png\n",
      "246: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_16.png\n",
      "247: (512, 512, 3)  image: 96-08919-4_CD8_ROI_1_mask.png\n",
      "247: (512, 512, 3)  mask:  96-08919-4_CD8_ROI_1.png\n",
      "248: (512, 512, 3)  image: 96-15186-C_CD3_ROI_7_mask.png\n",
      "248: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_7.png\n",
      "249: (512, 512, 3)  image: 10_CD8_ROI_8_mask.png\n",
      "249: (512, 512, 3)  mask:  10_CD8_ROI_8.png\n",
      "250: (512, 512, 3)  image: T1C03L1A2B1S11R01_ROI_8_mask.png\n",
      "250: (512, 512, 3)  mask:  T1C03L1A2B1S11R01_ROI_8.png\n",
      "251: (512, 512, 3)  image: T17-071841_III6_CD8_ROI_2_mask.png\n",
      "251: (512, 512, 3)  mask:  T17-071841_III6_CD8_ROI_2.png\n",
      "padding: 109x0\n",
      "252: (512, 512, 3)  image: 35_CD8_ROI_11_mask.png\n",
      "252: (512, 512, 3)  mask:  35_CD8_ROI_11.png\n",
      "253: (512, 512, 3)  image: 3_CD8_ROI_9_mask.png\n",
      "253: (512, 512, 3)  mask:  3_CD8_ROI_9.png\n",
      "254: (512, 512, 3)  image: T17-071549_III3_CD3_ROI_2_mask.png\n",
      "254: (512, 512, 3)  mask:  T17-071549_III3_CD3_ROI_2.png\n",
      "255: (512, 512, 3)  image: 13_CD8_ROI_16_mask.png\n",
      "255: (512, 512, 3)  mask:  13_CD8_ROI_16.png\n",
      "256: (512, 512, 3)  image: 28_CD8_ROI_16_mask.png\n",
      "256: (512, 512, 3)  mask:  28_CD8_ROI_16.png\n",
      "257: (512, 512, 3)  image: 13_CD8_ROI_11_mask.png\n",
      "257: (512, 512, 3)  mask:  13_CD8_ROI_11.png\n",
      "258: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_8_mask.png\n",
      "258: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_8.png\n",
      "259: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_12_mask.png\n",
      "259: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_12.png\n",
      "260: (512, 512, 3)  image: 95-06642-F1_CD3_ROI_8_mask.png\n",
      "260: (512, 512, 3)  mask:  95-06642-F1_CD3_ROI_8.png\n",
      "261: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_11_mask.png\n",
      "261: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_11.png\n",
      "262: (512, 512, 3)  image: 96-15186-C_CD3_ROI_6_mask.png\n",
      "262: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_6.png\n",
      "padding: 28x0\n",
      "263: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_14_mask.png\n",
      "263: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_14.png\n",
      "264: (512, 512, 3)  image: 95-30827-5_CD3_ROI_2_mask.png\n",
      "264: (512, 512, 3)  mask:  95-30827-5_CD3_ROI_2.png\n",
      "265: (512, 512, 3)  image: 31_CD3_ROI_10_mask.png\n",
      "265: (512, 512, 3)  mask:  31_CD3_ROI_10.png\n",
      "266: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_2_mask.png\n",
      "266: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_2.png\n",
      "267: (512, 512, 3)  image: T2C02L1A1B1S11R01_ROI_3_mask.png\n",
      "267: (512, 512, 3)  mask:  T2C02L1A1B1S11R01_ROI_3.png\n",
      "268: (512, 512, 3)  image: 19-CD3_ROI_1_mask.png\n",
      "268: (512, 512, 3)  mask:  19-CD3_ROI_1.png\n",
      "269: (512, 512, 3)  image: T10-4360_I_Y_CD8_ROI_3_mask.png\n",
      "269: (512, 512, 3)  mask:  T10-4360_I_Y_CD8_ROI_3.png\n",
      "270: (512, 512, 3)  image: T17-071841_III6_CD8_ROI_10_mask.png\n",
      "270: (512, 512, 3)  mask:  T17-071841_III6_CD8_ROI_10.png\n",
      "271: (512, 512, 3)  image: 31_CD3_ROI_9_mask.png\n",
      "271: (512, 512, 3)  mask:  31_CD3_ROI_9.png\n",
      "272: (512, 512, 3)  image: 19-CD3_ROI_6_mask.png\n",
      "272: (512, 512, 3)  mask:  19-CD3_ROI_6.png\n",
      "273: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_17_mask.png\n",
      "273: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_17.png\n",
      "274: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_8_mask.png\n",
      "274: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_8.png\n",
      "275: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_4_mask.png\n",
      "275: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_4.png\n",
      "276: (512, 512, 3)  image: 3_CD8_ROI_1_mask.png\n",
      "276: (512, 512, 3)  mask:  3_CD8_ROI_1.png\n",
      "277: (512, 512, 3)  image: 3_CD8_ROI_15_mask.png\n",
      "277: (512, 512, 3)  mask:  3_CD8_ROI_15.png\n",
      "padding: 83x0\n",
      "278: (512, 512, 3)  image: 3_CD8_ROI_8_mask.png\n",
      "278: (512, 512, 3)  mask:  3_CD8_ROI_8.png\n",
      "padding: 74x18\n",
      "279: (512, 512, 3)  image: 35_CD8_ROI_9_mask.png\n",
      "279: (512, 512, 3)  mask:  35_CD8_ROI_9.png\n",
      "280: (512, 512, 3)  image: 96-15186-C_CD3_ROI_8_mask.png\n",
      "280: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_8.png\n",
      "281: (512, 512, 3)  image: T2C02L1A1B1S11R01_ROI_5_mask.png\n",
      "281: (512, 512, 3)  mask:  T2C02L1A1B1S11R01_ROI_5.png\n",
      "282: (512, 512, 3)  image: 96-08919-4_CD8_ROI_6_mask.png\n",
      "282: (512, 512, 3)  mask:  96-08919-4_CD8_ROI_6.png\n",
      "283: (512, 512, 3)  image: T2C03L1A2B1S11R01_ROI_4_mask.png\n",
      "283: (512, 512, 3)  mask:  T2C03L1A2B1S11R01_ROI_4.png\n",
      "284: (512, 512, 3)  image: 31_CD3_ROI_8_mask.png\n",
      "284: (512, 512, 3)  mask:  31_CD3_ROI_8.png\n",
      "285: (512, 512, 3)  image: 96-15186-C_CD3_ROI_12_mask.png\n",
      "285: (512, 512, 3)  mask:  96-15186-C_CD3_ROI_12.png\n",
      "286: (512, 512, 3)  image: T17-071549_III5_CD3_ROI_8_mask.png\n",
      "286: (512, 512, 3)  mask:  T17-071549_III5_CD3_ROI_8.png\n",
      "287: (512, 512, 3)  image: 12-CD3_27.11.2014_17.27.31_ROI_1_mask.png\n",
      "287: (512, 512, 3)  mask:  12-CD3_27.11.2014_17.27.31_ROI_1.png\n",
      "288: (512, 512, 3)  image: T17-071549_III3_CD3_ROI_9_mask.png\n",
      "288: (512, 512, 3)  mask:  T17-071549_III3_CD3_ROI_9.png\n",
      "padding: 49x0\n",
      "289: (512, 512, 3)  image: 95-00909-II-L1_CD8_ROI_8_mask.png\n",
      "289: (512, 512, 3)  mask:  95-00909-II-L1_CD8_ROI_8.png\n",
      "padding: 63x0\n",
      "290: (512, 512, 3)  image: 3_CD8_ROI_13_mask.png\n",
      "290: (512, 512, 3)  mask:  3_CD8_ROI_13.png\n",
      "291: (512, 512, 3)  image: T10-4360_I_AG_CD3_ROI_9_mask.png\n",
      "291: (512, 512, 3)  mask:  T10-4360_I_AG_CD3_ROI_9.png\n"
     ]
    }
   ],
   "source": [
    "patches = generate_patches(train_dir, train_masks_dir, 300, 512, 512)\n",
    "mask_patches = []\n",
    "img_patches = []\n",
    "for patch in patches:\n",
    "    img_patches.append(np.array(patch[0]))\n",
    "    mask_patches.append(np.array(patch[1]))\n",
    "    \n",
    "#np.asarray(mask_patches)\n",
    "#np.asarray(img_patches)\n",
    "print(\"----------------------------\")\n",
    "print(\"{} image patches generated.\".format(len(img_patches)))\n",
    "print(\"{} mask patches generated.\".format(len(mask_patches)))\n",
    "print(\"img:  {}\".format(np.array(img_patches[0]).shape))\n",
    "print(\"mask: {}\".format(np.array(mask_patches[0]).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Augmentation\n",
    "*Not actually used at the moment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read images from disk and convert them to xyc format in a desire output range.\n",
    "def load_image(input_path, range_min=0, range_max=1):\n",
    "    \n",
    "    # Read image data (x, y, c) [0, 255]\n",
    "    image = Image.open(input_path)\n",
    "    \n",
    "    \n",
    "    half_the_width = image.size[0] / 2\n",
    "    half_the_height = image.size[1] / 2\n",
    "    image = image.crop(\n",
    "        (\n",
    "            half_the_width - 100,\n",
    "            half_the_height - 100,\n",
    "            half_the_width + 100,\n",
    "            half_the_height + 100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Convert image to the correct range\n",
    "    image = np.asarray(image) / 255\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define a function to plot a batch or list of image patches in a grid\n",
    "def plot_image(images, images_per_row=8):\n",
    "    \n",
    "    fig, axs = plt.subplots(int(np.ceil(len(images)/images_per_row)), images_per_row)\n",
    "    \n",
    "    c = 0\n",
    "    for ax_row in axs:\n",
    "        for ax in ax_row:\n",
    "            if c < len(images):\n",
    "                ax.imshow(images[c])\n",
    "            ax.axis('off')            \n",
    "            c += 1\n",
    "    plt.show()\n",
    "    \n",
    "training_paths = os.listdir(train_dir)\n",
    "validation_paths = os.listdir(validation_dir)\n",
    "\n",
    "training_images = [load_image(join(train_dir, path)) for path in training_paths[:50]]\n",
    "print('Some training examples (shape {shape}):'.format(shape=training_images[0].shape))\n",
    "plot_image(training_images[12:16], images_per_row=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=90,\n",
    "                                     horizontal_flip=True, \n",
    "                                     vertical_flip=True, \n",
    "                                     zoom_range=0.3, \n",
    "                                     width_shift_range=.3, \n",
    "                                     height_shift_range=.3)\n",
    "\n",
    "fake_labels = np.random.rand(len(training_images))\n",
    "fake_labels[fake_labels >= .5] = 1\n",
    "fake_labels[fake_labels < .5] = 0\n",
    "\n",
    "datagen.fit(training_images)\n",
    "\n",
    "for X_batch, y_batch in datagen.flow(np.array(training_images), fake_labels, batch_size=9):\n",
    "    plot_image(X_batch, images_per_row=3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Storing and getting patches \n",
    "Store everything in these objects to disk. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storepatchesondisk(patches, dirname):\n",
    "    #TODO\n",
    "    print('Patches stored!')\n",
    "\n",
    "def getpatchesfromdisk(dirname):\n",
    "    #TODO\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.5 Calulate Centroids and frame them\n",
    "Calculate the centroids per blob, filter for size and extent (a measure of how stringy the blob is) and then store it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareSubmissionData(image_names, images):\n",
    "    # define dataframe columns\n",
    "    columns = ['image_id_roi_id', 'pixel_size','x', 'y', 'score']\n",
    "   \n",
    "    #create the dataframe used to store coordinates\n",
    "    results = pd.DataFrame(columns=columns)\n",
    "    #per image get the list of centroids\n",
    "    for idx, image in enumerate(images):\n",
    "        \n",
    "        labels = skimage.measure.label(image, background=0)\n",
    "        regions = skimage.measure.regionprops(labels)\n",
    "        \n",
    "        #for each region found, add the data to the dataframe\n",
    "        for region in regions:\n",
    "            \n",
    "            # only select blobs that have more than 250 pixels/voxels. Arbitrary number, needs to be optimal\n",
    "            if region.area >= 250 and region.extent >= 0.6:\n",
    "                \n",
    "                temp = pd.DataFrame([['testje', 0.243094, region.centroid[0], region.centroid[1], 1]], columns=columns)\n",
    "                results = results.append(temp, ignore_index=True)\n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Networks\n",
    "This is where things go deep. The following two networks are defined\n",
    "\n",
    "* A \"stardard\" U-net that maxes out at 512\n",
    "* A copy of the U-net used to create a Retina U-net detector. Very specific approach and smaller than the standard u-net\n",
    "\n",
    "Additionally this section contains the following:\n",
    "* A method to calculate the f1-score\n",
    "* A method to save intermediate best networks\n",
    "* Some sanity checks: side-by-side plot of images and masks\n",
    "* Generating suitable training images\n",
    "* Model compilation \n",
    "* Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 U-net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_rows=512, img_cols=512, channels=3):\n",
    "    # A common problem is that Keras might automatically detect \"Channels first\" or last. The below notation is \"Channels last\"\n",
    "    # Which seems to be the default on cartesius. Problem, we only have once channel if we opt to only use the green channel\n",
    "    #\n",
    "    # Regarding input layer size - this does not seem to be our problem (Keras docs):\n",
    "    # When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers,\n",
    "    # does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in \n",
    "    # data_format=\"channels_last\".\n",
    "    \n",
    "    # So flattening also does not force the data into our format (e.g. by using a Flatten() layer)\n",
    "    \n",
    "    # Our error seems to be related to https://github.com/keras-team/keras/issues/6351 which includes many miracle fixes\n",
    "    # yet nothing for us.\n",
    "    \n",
    "    inputs = Input(shape=(None, None, channels))\n",
    "    s = keras.layers.core.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(s)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    " \n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    # we need to punish overfitting on background harshly until our model improves. Dice coef seems to get used often \n",
    "    # in literature, and kaggle. Using binary crossentropy for the moment. Before we were using categorical crossentropy\n",
    "    \n",
    "    sgd = keras.optimizers.SGD(lr=0.01) # Zanetta used 0.05, ours gets stuck in a local minimum and never improves. Probably related to training samples #\n",
    "    # however, we are now encountering this: a never changing loss and val_loss. \n",
    "    # https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Even Deeper U-net\n",
    "This one goes down to 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secondunet(img_rows=512, img_cols=512, channels=3):\n",
    "    # Deeper I go, deeper down\n",
    "    # Didn't think it could get any\n",
    "    # blacker\n",
    "    # The cold bites, the pressure\n",
    "    # builds\n",
    "    # I think I no longer matter\n",
    "    # https://www.youtube.com/watch?v=1-506_jiYkA\n",
    "    \n",
    "    inputs = Input(shape=(None, None, channels))\n",
    "    s = keras.layers.core.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(s)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    #512\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "    \n",
    "    #1024\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool5)\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    #512 again\n",
    "    up7 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv6), conv5], axis=3)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv7), conv4], axis=3)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv8), conv3], axis=3)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    up10 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv9), conv2], axis=3)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv10)\n",
    "\n",
    "    up11 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv10), conv1], axis=3)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv11)\n",
    " \n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid')(conv11)\n",
    "    model = Model(inputs=inputs, outputs=conv12)\n",
    "    # we need to punish overfitting on background harshly until our model improves. Dice coef seems to get used often \n",
    "    # in literature, and kaggle. Using binary crossentropy for the moment. Before we were using categorical crossentropy\n",
    "    \n",
    "    # Zanetta used a lr of 0.05, ours gets stuck in a local minimum and never improves. Probably related to training samples #\n",
    "    # however, we are now encountering this: a never changing loss and val_loss. \n",
    "    # https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network parameters, from Francesco's paper:\n",
    "\n",
    "* LR = 0.05\n",
    "* Dropouts 0.5 (when?)\n",
    "* SGD\n",
    "* CCR (cross-entropy) loss\n",
    "* F1-score\n",
    "\n",
    "* RGB threshold on training imgs\n",
    "\n",
    "Also 10 epochs with batch size 1. x20 resolution and 128x128 in- and output size \n",
    "\n",
    "## 2.3 F1-score\n",
    "f1-score based on what we had in week 7 or 8. Not used at the moment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    # Compute precision, recall and obtain several detection thresholds\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    \n",
    "    # Compute F1-score and remove numerical problems\n",
    "    f1 =  2 * (precision * recall) / (precision + recall)\n",
    "    f1 = f1[~np.isnan(f1)]\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Sanity check: plotting a patch and a corresponding mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(img_patches).shape) #should be (num_samples, 512, 512, 3)\n",
    "print(np.asarray(mask_patches).shape) #should be (num_samples, 512, 512)\n",
    "ino = 3\n",
    "\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "# for the record, matplotlib uses this short-hand notation to show subplots. The 121 here stands for 1 row, 2 columns, first img\n",
    "# now you know how to use subplots like a pro.\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_patches[ino])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_patches[ino])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 compile model and print model architecture. \n",
    "Also defines a model_checkpoint callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet(512, 512, num_channels)\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Prepare X_train and y_train sets\n",
    "* X_train contains the training samples (RGB)\n",
    "* y_train contains the labels as a binary map. Since the masks are generated as a 3-channel image earlier on, we just need to delete the two extra channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for img in img_patches:\n",
    "    X_train.append(np.asarray(img[:, :, :]))\n",
    "for msk in mask_patches:\n",
    "    y_train.append(np.asarray(msk[:, :,:]))\n",
    "\n",
    "y_train = np.delete(y_train, 2, 3)\n",
    "y_train = np.delete(y_train, 1, 3)\n",
    "\n",
    "#sanity checks.. what sizes are we dealing with?\n",
    "print(len(X_train))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Plot the mask again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate level sanity checks\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "# for the record, matplotlib uses this short-hand notation to show subplots. The 121 here stands for 1 row, 2 columns, first img\n",
    "# now you know how to use subplots like a pro.\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_patches[ino])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.squeeze(y_train[ino]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Finally train the model\n",
    "Train the model. If all goes well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One epoch generally takes 1 minute with batch size 1, 200 samples. Something to keep in mind..\n",
    "# the issues with the steady loss and val_loss seem to be related to the so-called dying relu problem. Go figure. Another problem to solve!\n",
    "# model.fit_generator(imgs_train, imgs_mask_train, batch_size=1, nb_epoch=10, verbose=1, shuffle=True, validation_split=0.2, callbacks=[model_checkpoint])\n",
    "model.fit(np.array(X_train), y_train, batch_size=8, epochs=20, verbose=1, shuffle=True, validation_split=0.2, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Using the Validation set for a sanity check\n",
    "The below code does the following things:\n",
    "\n",
    "* Load the best-yet model \n",
    "\n",
    "* load the validation images we've been supplied with\n",
    "* Generate masks for the validation images\n",
    "    * Creates a validation_masks_dir if there is none yet.\n",
    "    * Creates validation masks or loads them\n",
    "    * Creates patches for the validation set\n",
    "* Show side-by-side plots of the original validation image and the new mask\n",
    "\n",
    "* Shove one image in our best model and ask predict() what it makes out of it\n",
    "    * apply a threshold to the image\n",
    "* Plot the orgininal image, the defined mask, and the prediction side-by-side\n",
    "\n",
    "## 3.1 Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our best model\n",
    "model1 = keras.models.load_model('weights.h5') #saved by our callback earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Generate masks for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it does not exist already, create the validation masks folder\n",
    "validation_paths = os.listdir(validation_dir)\n",
    "if os.path.exists(validation_masks_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.system('mkdir -p ' + validation_masks_dir)\n",
    "\n",
    "# generate the masks if they are not already present on the system.\n",
    "mask_paths = os.listdir(validation_masks_dir)\n",
    "\n",
    "print('Found {} validation images.'.format(len(validation_paths))) # How many images do we actually have?\n",
    "\n",
    "for idx, path in enumerate(validation_paths):\n",
    "    mask_name = path.split('.png')[0] + '_mask.png'\n",
    "    if mask_name not in mask_paths:\n",
    "        print('Currently at image {}'.format(idx))\n",
    "        createMaskForImage(validation_dir, path, validation_points, validation_masks_dir, createCircularMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Generate patches for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vpatches = generate_patches(validation_dir, validation_masks_dir, 20, 512, 512)\n",
    "vmask_patches = []\n",
    "vimg_patches = []\n",
    "for patch in vpatches:\n",
    "    vimg_patches.append(np.array(patch[0]))\n",
    "    vmask_patches.append(np.array(patch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_p = []\n",
    "for img in vimg_patches:\n",
    "    val_images_p.append(np.asarray(img[:, :, :]))\n",
    "    \n",
    "#sanity checks.. what sizes are we dealing with?\n",
    "print(len(val_images_p))\n",
    "print(np.shape(val_images_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Check patches and masks from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show validation image and it's mask - Another sanity check\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "print(vimg_patches[0].shape)\n",
    "plt.imshow(vimg_patches[3])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(vmask_patches[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Make a prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "preds_val = model1.predict(np.asarray(val_images_p), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Threshold prediction\n",
    "May need to find a better way to do this at some point.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amin(preds_val)) # prints min\n",
    "print(np.ptp(preds_val)) # prints range\n",
    "print(np.amax(preds_val)) # prints max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold prediction\n",
    "preds_val = np.squeeze(preds_val) \n",
    "preds_val_t = (preds_val > 0.5)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amin(preds_val_t)) # prints min\n",
    "print(np.ptp(preds_val_t)) # prints range\n",
    "print(np.amax(preds_val_t)) # prints max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Checking prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check for checking image size\n",
    "print(np.shape(vimg_patches[0]))\n",
    "print(np.shape(preds_val[0])) \n",
    "print(np.shape(preds_val_t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subplot of 1 row\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "plt.suptitle('Example of a prediction on the validation set', fontsize=16)\n",
    "\n",
    "idx = 13 \n",
    "\n",
    "# plot original image\n",
    "plt.subplot(151)\n",
    "print(vimg_patches[idx].shape)\n",
    "plt.imshow(vimg_patches[idx])\n",
    "plt.title('Input data')\n",
    "\n",
    "#plot what the mask should have been\n",
    "plt.subplot(152)\n",
    "print(vmask_patches[idx].shape)\n",
    "plt.imshow(vmask_patches[idx])\n",
    "plt.title('Actual mask')\n",
    "\n",
    "#plot raw, unthresholded prediction\n",
    "plt.subplot(153)\n",
    "print(preds_val[idx].shape)\n",
    "plt.imshow(preds_val[idx])\n",
    "plt.title('Un-thresholded prediction')\n",
    "\n",
    "#plot thresholded prediction\n",
    "plt.subplot(154)\n",
    "plt.imshow(preds_val_t[idx], cmap='gray')\n",
    "plt.title('Thresholded Prediction')\n",
    "\n",
    "#plot labels using the measure tools\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# what this does is label the different blobs based on the connected component principle\n",
    "labels = label(preds_val_t[idx], background=0)\n",
    "\n",
    "# it should show even the tiniest specks as different blobs, this is of course undesirable because these are false positives!\n",
    "plt.subplot(155)\n",
    "plt.imshow(labels, cmap='spectral')\n",
    "plt.title('Identification of different clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just another validation of what we're seeing\n",
    "regions = regionprops(labels)\n",
    "\n",
    "for region in regions:\n",
    "    print('Number of pixels in blob: '+ format(region.area))\n",
    "    print('centroid coordinates of blob: '+format(region.centroid))\n",
    "    print('extent'+format(region.extent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get full images and their titles\n",
    "test_names = os.listdir(test_dir)\n",
    "X_test = []\n",
    "print('found:' + format(len(test_names))) # number of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(join(test_dir,test_names[2]))\n",
    "print(img.shape)\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "img_p = feature_extraction.image.extract_patches_2d(img, (512, 512), max_patches=3)\n",
    "\n",
    "print(img_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the first two pics of the test data\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(format(test_names[0]))\n",
    "plt.imshow(img_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model1.predict(img_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholding\n",
    "preds_test = np.squeeze(test_preds) \n",
    "preds_test_t = (preds_test > 0.5)*1.0\n",
    "print(test_preds.shape)\n",
    "print(preds_test.shape)\n",
    "print(preds_test_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subplot of 1 row\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "plt.suptitle('Example of a prediction on the tes set', fontsize=16)\n",
    "\n",
    "# plot original image\n",
    "plt.subplot(141)\n",
    "plt.imshow(np.squeeze(img_p[0]))\n",
    "plt.title('Input data')\n",
    "\n",
    "#plot raw, unthresholded prediction\n",
    "plt.subplot(142)\n",
    "plt.imshow(preds_test[0])\n",
    "plt.title('Un-thresholded prediction')\n",
    "\n",
    "#plot thresholded prediction\n",
    "plt.subplot(143)\n",
    "plt.imshow(preds_test_t[0], cmap='gray')\n",
    "plt.title('Thresholded Prediction')\n",
    "\n",
    "# what this does is label the different blobs based on the connected component principle\n",
    "labels = label(preds_test_t[0], background=0)\n",
    "\n",
    "# it should show even the tiniest specks as different blobs, this is of course undesirable because these are false positives!\n",
    "plt.subplot(144)\n",
    "plt.imshow(labels, cmap='spectral')\n",
    "plt.title('Identification of different clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try getting the image through the prepareSubmissionData function\n",
    "#preds_test_t = np.expand_dims(preds_test_t, axis=2)\n",
    "df = prepareSubmissionData(test_names[4], preds_test_t)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print to see if it looks right\n",
    "df.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"file.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Writing results to disk\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir for results\n",
    "result_dir = 'Results'\n",
    "# Create directory for the results (if not already existing)\n",
    "if os.path.exists(result_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.system('mkdir -p ' + result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Preparing a submission\n",
    "TODO using the code provided. We need to decide how we are going to find the centroid. I think Francesco has more knowledge on algorithms for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Evaluation on the test set\n",
    "\n",
    "## 4.1 training on the training + validation set\n",
    "More data is more better. Lets take the validation set as training data for our final model and using a split of 0.1 or 0.2?\n",
    "\n",
    "Also worth to be considered is training on full images!\n",
    "\n",
    "## 4.2 Loading test images\n",
    "TODO\n",
    "\n",
    "## 4.3 Make predictions on the test images\n",
    "TODO\n",
    "\n",
    "## 4.4 Store test prediction images\n",
    "TODO\n",
    "\n",
    "## 4.5 Calculate Lymphocyte centroids\n",
    "TODO\n",
    "\n",
    "## 4.6 Convert predictions to a csv submission\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - What is outside the flow of work\n",
    "Counting the number of lymphocytes was the goal of the project although the evaluation is based on the precision of the network. Therefore the following method returns the number of lymphocytes, given a sample image. \n",
    "\n",
    "## 5.1 Counting Lymps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count the number of lymphocytes in a given image\n",
    "def count_lymps(image):\n",
    "    num = skimage.measure.label(image,  return_num=True)[1]\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets test this with a mask!\n",
    "print('number of blobs: '+format(count_lymps(vmask_patches[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and other things that come up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.999 Print the time needed to execute the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- The entire notebook was done in %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
