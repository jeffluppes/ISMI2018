{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISMI2018 Lymphocyte Detection Project\n",
    "This is the main notebook for the final ISMI2018 project by Group 6.\n",
    "\n",
    "\n",
    "*Detection of lymphocytes in histopathology whole-slide images of breast, colon and prostate cancer, stained with immunohistochemistry*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team 6\n",
    "Our group consists out of four people:\n",
    "* **Brian Westerweel (Data Science)** - `B.Westerweel@student.ru.nl`\n",
    "* **Christoph Schmidl (Data Science)** - `c.schmidl@student.ru.nl`\n",
    "* **Gijs van der Meijde (Software Science)** - `G.vanderMeijde@student.ru.nl`\n",
    "* **Jeffrey Luppus (Data Science)** - `J.Luppes@student.ru.nl`\n",
    "\n",
    "*Supervisor: Francesco Ciompi*\n",
    "\n",
    "Group Github page: https://github.com/jeffluppes/ISMI2018 *feel free to work in branches.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```x``` = unavailable this date (e.g. unable to work on anything)\n",
    "* ```-``` = reduced availability (e.g. you might be able to skype or work a couple of hours)\n",
    "\n",
    "| Name  | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | *Notes* |\n",
    "|-------|---|---|---|---|---|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|---------|\n",
    "| Jeff  | - | - | x | x | x |  - |  - |  - |  - |    |  - |    |    |    |    |    |    |    |  x |    |    | *2 hrs a day for pet projects during work days, internship ends 15th* |\n",
    "| Gijs  | x | x | x | x | x |  x |  x |  x |  x |  x |  - |    |    |  - |  - |    |  - |    |    |    |    | *has short term deadline until the 14th*        |\n",
    "| Brian |   |   |   | - | - |  x |  x |  - |  - |  - |  - |  x |  x |  - |  - |  - |  - | x  |  x |  x |    |         |\n",
    "| Chris |   |   |   |   |   |    |  x |  x |  x |  x |    |    |    |    |  x |  x |  x |    |    |    |    |         | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals for this week (June 11 to June 18)\n",
    "\n",
    "**MAIN GOALS**\n",
    "* Use all of the training and validation data that we have available\n",
    "* ~~Implement a function to return the coordinates of a mask (centroid calculation)~~\n",
    "* Saving predictions (images) to disk\n",
    "* ~~Make a submission file~~\n",
    "* Use generator and make sensible augmentations\n",
    "* Make annotations with open source tools \n",
    "* Make our first submission\n",
    "\n",
    "**Other goals:**\n",
    "\n",
    "* Implement loss plotting function\n",
    "* Implement early stopping\n",
    "* Implement a custom loss function\n",
    "* Run predictions on the entire validation set\n",
    "\n",
    "**Backlog and minor TODOs**\n",
    "* Implement image warping\n",
    "* Get data augmentation working\n",
    "* Implement a function to count lymphocytes\n",
    "\n",
    "Be aware of the following:\n",
    "\n",
    "* **Next contact moment**: Monday at 10 skype call > New moment to be scheduled\n",
    "* **Next group meeting**: Friday and Monday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Deadlines\n",
    "\n",
    "* ~~**Mid-term presentation:** June 4, 9:00 - 12:00, room 616 Huygen building~~\n",
    "* **Deadline project:** 25th of june\n",
    "* **Final presentation:** July 2, 9:00 - 12:00, room 616 Huygen building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "The two papers Francesco sent:\n",
    "\n",
    "* https://openreview.net/pdf?id=rk0xLisiM\n",
    "* https://openreview.net/pdf?id=S10IfW2oz\n",
    "\n",
    "Kaggle Contest about cell detection (Data Science Bowl 2018)\n",
    "\n",
    "* https://www.kaggle.com/c/data-science-bowl-2018\n",
    "\n",
    "Particular Kernels of Interest (KoIs)\n",
    "\n",
    "* https://www.kaggle.com/weiji14/yet-another-keras-u-net-data-augmentation\n",
    "* https://www.kaggle.com/piotrczapla/tensorflow-u-net-starter-lb-0-34\n",
    "* https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277?scriptVersionId=2164855\n",
    "\n",
    "Other resources\n",
    "\n",
    "* https://spark-in.me/post/unet-adventures-part-one-getting-acquainted-with-unet\n",
    "* https://towardsdatascience.com/medical-image-segmentation-part-1-unet-convolutional-networks-with-interactive-code-70f0f17f46c6 (Christoph)\n",
    "* https://colab.research.google.com/drive/1BgCDxVdVc0MAe_kC0waMGUV9ShcWW0hM (Christoph)\n",
    "* https://keunwoochoi.wordpress.com/2017/10/11/u-net-on-keras-2-0/ (Jeff)\n",
    "* https://github.com/jocicmarko/ultrasound-nerve-segmentation (Jeff)\n",
    "* https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/ (Gijs)\n",
    "\n",
    "### MOOCs if you have spare time to waste (I havent)\n",
    "http://course.fast.ai/part2.html\n",
    "http://course.fast.ai/lessons/lesson14.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "from os.path import join, basename, dirname, exists  \n",
    "import os  \n",
    "from glob import glob\n",
    "import csv\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 2201136600 #because Pillow will whine to no end if you feed it big images. You're welcome.\n",
    "import math\n",
    "\n",
    "# Computational\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from matplotlib import pyplot as plt  \n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Flatten, Dropout, UpSampling2D, core\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Other\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import sklearn\n",
    "from scipy.ndimage import imread  \n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Tracking time\n",
    "This tracks the computation time for the entire notebook. See results in the last cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user = 'ruc0028' # Jeffrey = True\n",
    "user = 'ruc0030' # Gijs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesius file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/train_images'\n",
    "validation_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/validation_images'\n",
    "test_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/test_images'\n",
    "train_points = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/training_annotations.csv'\n",
    "validation_points = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/validation_annotations.csv' #new\n",
    "data_dir = 'data'\n",
    "train_masks_dir = data_dir+'/train_masks'\n",
    "validation_masks_dir = data_dir+'/validation_masks'\n",
    "results_dir = 'Results'\n",
    "\n",
    "num_channels = 3  #changing this breaks the entire thing but just so you know we include it as an option. \n",
    "\n",
    "gen_patches = False #Whether or not you want to generate new patches. Keep false to use patches stored on disk\n",
    "train_patches_dir = data_dir+'/train_patches'\n",
    "validation_patches_dir = data_dir+'/validation_patches'\n",
    "\n",
    "#Globals for patches.\n",
    "global_width = 512\n",
    "global_height = 512\n",
    "global_patch_amount = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in train csv and show what we've got\n",
    "train_annotations = pd.read_csv(train_points, index_col=False)\n",
    "train_annotations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations[' pixel_size'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What to gather from this?**\n",
    "\n",
    "We have 50811 points, the pixel sizes vary from 0.12 to 0.24 but the mean is much closer to 0.24 indicating a skewed distribution. Yet, it's good to keep in mind the varying sizes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics on the training data\n",
    "So the annotations file has the locations of each annotated cell. It would be good to know how many lymphocytes per ROI we can expect. The below query produces an ordered list per image and ROI of how many annotations we have per combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annotations per image, bear in mind this only actually obtains the ROIs that have lymphocytes\n",
    "# note: this specifically returns a dataframe instead of a series so we can plot it with ease\n",
    "df = train_annotations.groupby([' roi_id','image_id']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "df.index.name = 'Combination_id'\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the jupyter server runs locally (Brian, Gijs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttrain_dir = 'train_images'\n",
    "#ttrain_masks_dir = 'train_masks'\n",
    "#train_points = 'training_annotations.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Housekeeping\n",
    "This section defines the convenience methods needed for processing the images.\n",
    "\n",
    "* Creating various masks (used as ground truth)\n",
    "    * Square Masks\n",
    "    * Elipse Masks\n",
    "    * Circular Masks\n",
    "    * Mask creation\n",
    "* Creating patches\n",
    "    * Patch generation\n",
    "* Data augmentation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    return x.split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSquareMask(h, w, center, radius):\n",
    "    mask = np.zeros((h, w), dtype=bool)\n",
    "    lb = center[0] - radius\n",
    "    rb = center[0] + radius\n",
    "    ub = center[1] - radius\n",
    "    bb = center[1] + radius\n",
    "    mask[ub:bb, lb:rb] = True\n",
    "    return mask\n",
    "\n",
    "def createElipseMask(h, w, center, radius):\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + 2*(Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "\n",
    "def createCircularMask(h, w, center, radius):\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "    \n",
    "\n",
    "def createMaskForImage(img_dir, image_path, center_csv, mask_dir, mask_fn):\n",
    "    image_name = image_path.split('.png')[0]\n",
    "    image_id, roi = image_name.split('_ROI_')\n",
    "    print('Processing {}'.format(image_name))\n",
    "    \n",
    "    image = plt.imread(join(img_dir, image_path))\n",
    "    mask = np.zeros((image.shape[0], image.shape[1]))\n",
    "    pixel_size = 0.24309392273426056 # is this the same for each image?\n",
    "     \n",
    "    radius = 2.5 / pixel_size #Brian's was 3.5.\n",
    "    \n",
    "    pois = []\n",
    "    with open(center_csv) as file:\n",
    "        pois = list(map(split, file.readlines()[1:]))\n",
    "    \n",
    "    pois = [poi for poi in pois if (poi[0] == image_id and poi[1] == roi)]\n",
    "\n",
    "    \n",
    "    print('Found {} lymphocytes in this image.'.format(len(pois))) # How many lymps are annotated here?\n",
    "    for poi in pois:\n",
    "        x = int(float(poi[3]))\n",
    "        y = int(float(poi[4]))\n",
    "        shape_mask = mask_fn(image.shape[0], image.shape[1], [x, y], radius)\n",
    "        mask[shape_mask] = 1\n",
    "        \n",
    "    mask_image = Image.fromarray(np.uint8(mask*255), 'L')\n",
    "    mask_image.save(join(mask_dir, image_name + '_mask.png'))\n",
    "    print('Created a mask for: {}'.format(image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_paths = os.listdir(train_dir)\n",
    "mask_paths = os.listdir(train_masks_dir)\n",
    "print('Found {} training images for patch generation.'.format(len(training_paths))) # How many images do we actually have?\n",
    "\n",
    "# Go through the masks, print progress because this is a long job!\n",
    "for idx, path in enumerate(training_paths):\n",
    "\n",
    "    mask_name = path.split('.png')[0] + '_mask.png'\n",
    "    if mask_name not in mask_paths:\n",
    "        print('Currently at image {}'.format(idx))\n",
    "        createMaskForImage(train_dir, path, train_points, train_masks_dir, createElipseMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Patch Generator\n",
    "We experimented with multiple ways of generating patches. In this part of the Notebook the different patch generators are implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Split patches\n",
    "This patch generator splits the images that have a mask into smaller images of given dementions. If the sub-image contains lymphocytes it, and its mask, will be added to the list of patches. This patch generator stops when the patch_amount is reached. if patch_amount <= 0 it will generate patches for all images that have a mask.\n",
    "\n",
    "Example call: *generate_split_patches(train_dir, train_masks_dir, 0, global_width, global_height, train_points)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_img_in_patches(img, msk, width, height, pois):\n",
    "    horizontal_amount = math.floor(img.shape[0]/width)\n",
    "    vertical_amount   = math.floor(img.shape[1]/height)\n",
    "    patches = []\n",
    "    print(\"getting {}*{}={} patches from image (dimensions:{}x{})\".format(horizontal_amount, vertical_amount, horizontal_amount*vertical_amount, img.shape[0], img.shape[1]))\n",
    "    for x in range(0, horizontal_amount):\n",
    "        for y in range(0, vertical_amount):\n",
    "            x1 = x*width\n",
    "            y1 = y*height\n",
    "            lymps = [poi for poi in pois if (float(poi[3]) >= x and float(poi[3]) <= x1 and float(poi[4]) >= y and float(poi[4]) <= y1)]\n",
    "            if(len(lymps) > 0):\n",
    "                patches.append( (np.array(img[x:x1,y:y1,:]), np.array(msk[x:x1,y:y1])) )\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if patch_amount <= 0 all images that have a mask will be patched!\n",
    "def generate_split_patches(img_dir, msk_dir, patch_amount, width, height, csv_file):\n",
    "    patches = []\n",
    "    all_img_paths = os.listdir(img_dir)\n",
    "    img_paths = random.sample(all_img_paths, patch_amount)\n",
    "    with open(csv_file) as file:\n",
    "        pois = list(map(split, file.readlines()[1:]))\n",
    "    msk_paths = os.listdir(msk_dir)\n",
    "    for msk_path in msk_paths:\n",
    "        img_base_name = msk_path.split(\"_mask\")[0]\n",
    "        img_id, roi = img_base_name.split('_ROI_')\n",
    "        _pois = [poi for poi in pois if (poi[0] == img_id and poi[1] == roi)]\n",
    "        print(\"patching {}\".format(img_base_name+\".png\"))\n",
    "        patches.extend(split_img_in_patches(imread(join(img_dir,img_base_name+\".png\")), imread(join(msk_dir,img_base_name+\"_mask.png\")), width, height, _pois))\n",
    "        if(patch_amount > 0 and len(patches)>=patch_amount):\n",
    "            break\n",
    "    print(\"FINISHED PATCHING\")\n",
    "    return patches if (patch_amount < 1) else patches[:patch_amount]\n",
    "        \n",
    "#generate_split_patches(train_dir, train_masks_dir, 0, global_width, global_height, train_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 'Best' patches\n",
    "This patch generator checks the .csv file for the patch (of given dimensions) on an image that contains the most lymphocytes.\n",
    "This patch, and its mask, will be added to the list of patches. This patch generator is 'embedded' in the next patch generator and can be called by toggling the last boolean parameter to True.\n",
    "\n",
    "Example call: *generate_patches(train_dir, train_masks_dir, 300, global_width, global_height, train_points, True)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_patch_coordinate(csv_file, img_id, roi, width, height):\n",
    "    best_x_coord = 0\n",
    "    best_y_coord = 0\n",
    "    with open(csv_file) as file:\n",
    "        pois = list(map(split, file.readlines()[1:]))\n",
    "    pois = [poi for poi in pois if (poi[0] == img_id and poi[1] == roi)]\n",
    "    best_x_coord = get_best_from_column(pois, width, 3)\n",
    "    pois = [poi for poi in pois if (float(poi[3]) >= best_x_coord and float(poi[3]) <= best_x_coord + width)]\n",
    "    best_y_coord = get_best_from_column(pois, height, 4)\n",
    "    print(\"Best coordinate for {}_ROI_{} is {}X{}\".format(img_id, roi, int(best_x_coord), int(best_y_coord)))\n",
    "    return (best_x_coord, best_y_coord)\n",
    "    \n",
    "def get_best_from_column(pois, length, column):\n",
    "    best_coord = 0\n",
    "    best_amount = 0\n",
    "    for i in range(0, len(pois)):\n",
    "        cur_coord = float(pois[i][column])\n",
    "        cur_amount = len([poi for poi in pois if (float(poi[column]) >= cur_coord and float(poi[column]) <= cur_coord + length)])\n",
    "        if(cur_amount > best_amount):\n",
    "            best_coord = cur_coord\n",
    "            best_amount = cur_amount\n",
    "    print(\"best index on column {} is {}  ({} results)\".format(column, best_coord, best_amount))\n",
    "    return best_coord "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING get_best_patch_coordinate function\n",
    "def test_get_best_patch_coordinate():\n",
    "    #all_img_paths = os.listdir(train_dir)\n",
    "    #img_name = random.sample(all_img_paths, 1)[0].split(\".png\")[0]\n",
    "    img_name = \"31_CD3_ROI_8\"\n",
    "    img_id, roi = img_name.split('_ROI_')\n",
    "    _img = imread(join(train_dir,img_name+\".png\"))\n",
    "    _msk = imread(join(train_masks_dir,img_name+\"_mask.png\"))\n",
    "    coord = get_best_patch_coordinate(train_points, img_id, roi, global_width, global_height)\n",
    "    x = int(coord[0])\n",
    "    x1 = x + global_width\n",
    "    y = int(coord[1])\n",
    "    y1 = y + global_height\n",
    "    plt.figure(1, figsize=(18, 6))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(_img[x:x1,y:y1,:])\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(_msk[x:x1,y:y1])\n",
    "    \n",
    "test_get_best_patch_coordinate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Random patches\n",
    "This patch generator generates random patches that contain at least 1 lymphocyte. Duplicate patches should not occur.\n",
    "To use random patch generation toggle the last boolean parameter to False.\n",
    "\n",
    "Example call: *generate_patches(train_dir, train_masks_dir, 300, global_width, global_height, train_points, False)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_log = []\n",
    "coord_tries = []\n",
    "def get_random_patch_coordinate(csv_file, img_id, roi, width, height):\n",
    "    #img_name = img_path.split('.png')[0]\n",
    "    #img_id, roi = img_name.split('_ROI_')\n",
    "    pois = []\n",
    "    \n",
    "    with open(csv_file) as file:\n",
    "        pois = list(map(split, file.readlines()[1:]))\n",
    "    pois = [poi for poi in pois if (poi[0] == img_id)]\n",
    "    while(len(coord_tries) < len(pois)):\n",
    "        #for poi in pois:\n",
    "        p = random.randint(0,len(pois)-1)\n",
    "        while(p in coord_tries):\n",
    "            p = random.randint(0,len(pois)-1)\n",
    "        coord_tries.append(p)\n",
    "        poi = pois[p]\n",
    "        x = int(float(poi[3]))\n",
    "        y = int(float(poi[4]))\n",
    "        if( (x,y) in patch_log):\n",
    "            return None\n",
    "        patch_log.append( (x,y) )\n",
    "        return (round(x - (width/2)), round(y - (height/2)))\n",
    "    return (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING get_best_random_coordinate function\n",
    "def test_get_random_patch_coordinate():\n",
    "    all_img_paths = os.listdir(train_dir)\n",
    "    img_name = random.sample(all_img_paths, 1)[0].split(\".png\")[0]\n",
    "    img_id, roi = img_name.split('_ROI_')\n",
    "    _img = imread(join(train_dir,img_name+\".png\"))\n",
    "    _msk = imread(join(train_masks_dir,img_name+\"_mask.png\"))\n",
    "    coord = get_random_patch_coordinate(train_points, img_id, roi, global_width, global_height)\n",
    "    print(\"Random coordinate for {} is {}X{}\".format(img_name, int(coord[0]), int(coord[1])))\n",
    "    x = int(coord[0])\n",
    "    x1 = x + global_width\n",
    "    y = int(coord[1])\n",
    "    y1 = y + global_height\n",
    "    plt.figure(1, figsize=(18, 6))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(_img[x:x1,y:y1,:])\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(_msk[x:x1,y:y1])\n",
    "    \n",
    "test_get_random_patch_coordinate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function generates 1 random patch from patch_amount random images.\n",
    "\n",
    "def generate_patches(img_dir, msk_dir, patch_amount, width, height, csv_file, best_patches):\n",
    "    patches = []\n",
    "    all_img_paths = os.listdir(img_dir)\n",
    "    img_paths = random.sample(all_img_paths, patch_amount)\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "        img_name = img_path.split('.png')[0]\n",
    "        msk_path = img_name + '_mask.png'\n",
    "        img = imread(join(img_dir,img_path))\n",
    "        msk = imread(join(msk_dir, msk_path)) # changed june 1 to include params\n",
    "        msk = np.stack((msk,)*3, 2)\n",
    "\n",
    "        coord = (0,0)\n",
    "        img_id, roi = img_name.split('_ROI_')\n",
    "        if(best_patches == True):\n",
    "            coord = get_best_patch_coordinate(csv_file, img_id, roi, width, height)\n",
    "        else:\n",
    "            coord = get_random_patch_coordinate(csv_file, img_id, roi, width, height)\n",
    "        \n",
    "        if(coord != None):\n",
    "            patch = generate_patch(img,msk,width,height, coord)\n",
    "            patches.append(patch)\n",
    "            print(\"{}: {}  image: {}\".format(len(patches), patch[0].shape, msk_path))\n",
    "    while(best_patches == False and len(patches) < patch_amount):\n",
    "        print(\"only {} out of {} patches could be generated, recursing now\".format(len(patches), patch_amount))\n",
    "        np.append(patches, generate_patches(img_dir, msk_dir, patch_amount - (len(patches) -1), width, height), axis=0)\n",
    "    return patches\n",
    "\n",
    "#This function generates a single random patch from an image.\n",
    "def generate_patch(img, msk, width, height, coord):\n",
    "    padHeight = 0 if height < img.shape[1] else height-img.shape[1]\n",
    "    padWidth  = 0 if width < img.shape[0] else width-img.shape[0]\n",
    "    if(img.shape[0] < width or img.shape[1] < height):\n",
    "        print(\"padding: {}x{}\".format(padWidth, padHeight))\n",
    "    img = np.pad(img, [(0,padWidth), (0, padHeight), (0,0 )], mode='constant')\n",
    "    msk = np.pad(msk, [(0,padWidth), (0, padHeight), (0,0 )], mode='constant')\n",
    "    x = int(coord[0])\n",
    "    x1 = x + width\n",
    "    y = int(coord[1])\n",
    "    y1 = y + height\n",
    "    if x1 > img.shape[0]:\n",
    "        print(\"WARNING x out of bounds ({} > {}). Correcting coordinate to fit image.\".format(x1,img.shape[0]))\n",
    "        x1 = img.shape[0]\n",
    "        x = x1 - width\n",
    "    if y1 > img.shape[1]:\n",
    "        print(\"WARNING y out of bounds ({} > {}). Correcting coordinate to fit image.\".format(y1,img.shape[1]))\n",
    "        y1 = img.shape[1]\n",
    "        y = y1 - height\n",
    "    return (np.array(img[x:x1,y:y1,:]), np.array(msk[x:x1,y:y1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Patch generation\n",
    "Here we generate the actual patches that are used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate patches!\n",
    "patches = generate_patches(train_dir, train_masks_dir, global_patch_amount, global_width, global_height, train_points, True)\n",
    "#patches = generate_patches(train_dir, train_masks_dir, global_patch_amount, global_width, global_height, train_points, False)\n",
    "mask_patches = []\n",
    "img_patches = []\n",
    "for patch in patches:\n",
    "    img_patches.append(np.array(patch[0]))\n",
    "    mask_patches.append(np.array(patch[1]))\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"{} image patches generated.\".format(len(img_patches)))\n",
    "print(\"{} mask patches generated.\".format(len(mask_patches)))\n",
    "print(\"img:  {}\".format(np.array(img_patches[0]).shape))\n",
    "print(\"mask: {}\".format(np.array(mask_patches[0]).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Augmentation\n",
    "*Not actually used at the moment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read images from disk and convert them to xyc format in a desire output range.\n",
    "def load_image(input_path, range_min=0, range_max=1):\n",
    "    \n",
    "    # Read image data (x, y, c) [0, 255]\n",
    "    image = Image.open(input_path)\n",
    "    \n",
    "    \n",
    "    half_the_width = image.size[0] / 2\n",
    "    half_the_height = image.size[1] / 2\n",
    "    image = image.crop(\n",
    "        (\n",
    "            half_the_width - 100,\n",
    "            half_the_height - 100,\n",
    "            half_the_width + 100,\n",
    "            half_the_height + 100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Convert image to the correct range\n",
    "    image = np.asarray(image) / 255\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define a function to plot a batch or list of image patches in a grid\n",
    "def plot_image(images, images_per_row=8):\n",
    "    \n",
    "    fig, axs = plt.subplots(int(np.ceil(len(images)/images_per_row)), images_per_row)\n",
    "    \n",
    "    c = 0\n",
    "    for ax_row in axs:\n",
    "        for ax in ax_row:\n",
    "            if c < len(images):\n",
    "                ax.imshow(images[c])\n",
    "            ax.axis('off')            \n",
    "            c += 1\n",
    "    plt.show()\n",
    "    \n",
    "training_paths = os.listdir(train_dir)\n",
    "validation_paths = os.listdir(validation_dir)\n",
    "\n",
    "training_images = [load_image(join(train_dir, path)) for path in training_paths[:50]]\n",
    "print('Some training examples (shape {shape}):'.format(shape=training_images[0].shape))\n",
    "plot_image(training_images[12:16], images_per_row=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=90,\n",
    "                                     horizontal_flip=True, \n",
    "                                     vertical_flip=True, \n",
    "                                     zoom_range=0.3, \n",
    "                                     width_shift_range=.3, \n",
    "                                     height_shift_range=.3)\n",
    "\n",
    "fake_labels = np.random.rand(len(training_images))\n",
    "fake_labels[fake_labels >= .5] = 1\n",
    "fake_labels[fake_labels < .5] = 0\n",
    "\n",
    "datagen.fit(training_images)\n",
    "\n",
    "for X_batch, y_batch in datagen.flow(np.array(training_images), fake_labels, batch_size=9):\n",
    "    plot_image(X_batch, images_per_row=3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Storing and getting patches \n",
    "Store everything in these objects to disk. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storepatchesondisk(patches, dirname):\n",
    "    #TODO\n",
    "    print('Patches stored!')\n",
    "\n",
    "def getpatchesfromdisk(dirname):\n",
    "    #TODO\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.5 Calulate Centroids and frame them\n",
    "Calculate the centroids per blob, filter for size and extent (a measure of how stringy the blob is) and then store it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareSubmissionData(image_name, images):\n",
    "    # define dataframe columns\n",
    "    columns = ['image_id_roi_id', 'pixel_size','x', 'y', 'score']\n",
    "   \n",
    "    #create the dataframe used to store coordinates\n",
    "    results = pd.DataFrame(columns=columns)\n",
    "    #per image get the list of centroids\n",
    "    for idx, image in enumerate(images):\n",
    "        \n",
    "        labels = skimage.measure.label(image, background=0)\n",
    "        regions = skimage.measure.regionprops(labels)\n",
    "        \n",
    "        #for each region found, add the data to the dataframe\n",
    "        for region in regions:\n",
    "            \n",
    "            # only select blobs that have more than 250 pixels/voxels. Arbitrary number, needs to be optimal\n",
    "            if region.area >= 250 and region.extent >= 0.6:\n",
    "                \n",
    "                temp = pd.DataFrame([[image_name, 0.243094, region.centroid[0], region.centroid[1], 1]], columns=columns)\n",
    "                results = results.append(temp, ignore_index=True)\n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - The U-net Zoo\n",
    "This is where things go deep. The following  networks are defined\n",
    "\n",
    "* A tiny one that maxes out at 64 (tinynet)\n",
    "* A \"stardard\" U-net that maxes out at 128 (smallnet)\n",
    "* A deeper one that maxes out at 256 (mednet)\n",
    "* A \"stardard\" U-net that maxes out at 512 (unet)\n",
    "* A deeper one that maxes out at 1024 (yugenet)\n",
    "\n",
    "Additionally this section contains the following:\n",
    "\n",
    "* A method to save intermediate best networks\n",
    "* Some sanity checks: side-by-side plot of images and masks\n",
    "* Generating suitable training images\n",
    "* Model compilation \n",
    "* Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tinynet(img_rows=512, img_cols=512, channels=3):\n",
    "    inputs = Input(shape=(None, None, channels))\n",
    "    s = keras.layers.core.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(s)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "\n",
    "    up3 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv2), conv1], axis=3)\n",
    "    conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(up3)\n",
    "    conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3)\n",
    " \n",
    "    conv4 = Conv2D(1, (1, 1), activation='sigmoid')(conv3)\n",
    "    model = Model(inputs=inputs, outputs=conv4)\n",
    "    \n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smallnet(img_rows=512, img_cols=512, channels=3):\n",
    "    inputs = Input(shape=(None, None, channels))\n",
    "    s = keras.layers.core.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(s)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "    up4 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv3), conv2], axis=3)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv4), conv1], axis=3)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up5)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
    " \n",
    "    conv6 = Conv2D(1, (1, 1), activation='sigmoid')(conv5)\n",
    "    model = Model(inputs=inputs, outputs=conv6)\n",
    "    \n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mednet(img_rows=512, img_cols=512, channels=3):\n",
    "    inputs = Input(shape=(None, None, channels))\n",
    "    s = keras.layers.core.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(s)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3)\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(up5)\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv5), conv2], axis=3)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv6), conv1], axis=3)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    " \n",
    "    conv8 = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
    "    model = Model(inputs=inputs, outputs=conv8)\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_rows=global_height, img_cols=global_width, channels=num_channels):\n",
    "    # A common problem is that Keras might automatically detect \"Channels first\" or last. The below notation is \"Channels last\"\n",
    "    # Which seems to be the default on cartesius. Problem, we only have once channel if we opt to only use the green channel\n",
    "    #\n",
    "    # Regarding input layer size - this does not seem to be our problem (Keras docs):\n",
    "    # When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers,\n",
    "    # does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in \n",
    "    # data_format=\"channels_last\".\n",
    "    \n",
    "    # So flattening also does not force the data into our format (e.g. by using a Flatten() layer)\n",
    "    \n",
    "    # Our error seems to be related to https://github.com/keras-team/keras/issues/6351 which includes many miracle fixes\n",
    "    # yet nothing for us.\n",
    "    \n",
    "    inputs = Input(shape=(None, None, channels))\n",
    "    s = keras.layers.core.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(s)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    " \n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    # we need to punish overfitting on background harshly until our model improves. Dice coef seems to get used often \n",
    "    # in literature, and kaggle. Using binary crossentropy for the moment. Before we were using categorical crossentropy\n",
    "    \n",
    "    sgd = keras.optimizers.SGD(lr=0.01) # Zanetta used 0.05, ours gets stuck in a local minimum and never improves. Probably related to training samples #\n",
    "    # however, we are now encountering this: a never changing loss and val_loss. \n",
    "    # https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 An Even Deeper U-net\n",
    "This one goes down to 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yugenet(img_rows=512, img_cols=512, channels=3):\n",
    "    # Deeper I go, deeper down\n",
    "    # Didn't think it could get any\n",
    "    # blacker\n",
    "    # The cold bites, the pressure\n",
    "    # builds\n",
    "    # I think I no longer matter\n",
    "    # https://www.youtube.com/watch?v=1-506_jiYkA\n",
    "    \n",
    "    inputs = Input(shape=(None, None, channels))\n",
    "    s = keras.layers.core.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(s)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    #512\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "    \n",
    "    #1024\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool5)\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    #512 again\n",
    "    up7 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv6), conv5], axis=3)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv7), conv4], axis=3)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv8), conv3], axis=3)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    up10 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv9), conv2], axis=3)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv10)\n",
    "\n",
    "    up11 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv10), conv1], axis=3)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv11)\n",
    " \n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid')(conv11)\n",
    "    model = Model(inputs=inputs, outputs=conv12)\n",
    "    # we need to punish overfitting on background harshly until our model improves. Dice coef seems to get used often \n",
    "    # in literature, and kaggle. Using binary crossentropy for the moment. Before we were using categorical crossentropy\n",
    "    \n",
    "    # Zanetta used a lr of 0.05, ours gets stuck in a local minimum and never improves. Probably related to training samples #\n",
    "    # however, we are now encountering this: a never changing loss and val_loss. \n",
    "    # https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks\n",
    "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network parameters, from Francesco's paper:\n",
    "\n",
    "* LR = 0.05\n",
    "* Dropouts 0.5 (when?)\n",
    "* SGD\n",
    "* CCR (cross-entropy) loss\n",
    "* F1-score\n",
    "\n",
    "* RGB threshold on training imgs\n",
    "\n",
    "Also 10 epochs with batch size 1. x20 resolution and 128x128 in- and output size \n",
    "\n",
    "## 2.3 F1-score\n",
    "f1-score based on what we had in week 7 or 8. Not used at the moment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  f1_scoref1_score(y_true, y_pred):\n",
    "    # Compute precision, recall and obtain several detection thresholds\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    \n",
    "    # Compute F1-score and remove numerical problems\n",
    "    f1 =  2 * (precision * recall) / (precision + recall)\n",
    "    f1 = f1[~np.isnan(f1)]\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Sanity check: plotting a patch and a corresponding mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(img_patches).shape) #should be (num_samples, 512, 512, 3)\n",
    "print(np.asarray(mask_patches).shape) #should be (num_samples, 512, 512)\n",
    "ino = 3\n",
    "\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "# for the record, matplotlib uses this short-hand notation to show subplots. The 121 here stands for 1 row, 2 columns, first img\n",
    "# now you know how to use subplots like a pro.\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_patches[ino])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_patches[ino])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 compile model and print model architecture. \n",
    "Also defines a model_checkpoint callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_smallnet(global_width, global_height, num_channels)\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Prepare X_train and y_train sets\n",
    "* X_train contains the training samples (RGB)\n",
    "* y_train contains the labels as a binary map. Since the masks are generated as a 3-channel image earlier on, we just need to delete the two extra channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for img in img_patches:\n",
    "    X_train.append(np.asarray(img[:, :, :]))\n",
    "for msk in mask_patches:\n",
    "    y_train.append(np.asarray(msk[:, :,:]))\n",
    "\n",
    "y_train = np.delete(y_train, 2, 3)\n",
    "y_train = np.delete(y_train, 1, 3)\n",
    "\n",
    "#sanity checks.. what sizes are we dealing with?\n",
    "print(len(X_train))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Plot the mask again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate level sanity checks\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "# for the record, matplotlib uses this short-hand notation to show subplots. The 121 here stands for 1 row, 2 columns, first img\n",
    "# now you know how to use subplots like a pro.\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_patches[ino])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.squeeze(y_train[ino]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Finally train the model\n",
    "Train the model. If all goes well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One epoch generally takes 1 minute with batch size 1, 200 samples. Something to keep in mind..\n",
    "# the issues with the steady loss and val_loss seem to be related to the so-called dying relu problem. Go figure. Another problem to solve!\n",
    "# model.fit_generator(imgs_train, imgs_mask_train, batch_size=1, nb_epoch=10, verbose=1, shuffle=True, validation_split=0.2, callbacks=[model_checkpoint])\n",
    "model.fit(np.array(X_train), y_train, batch_size=8, epochs=4, verbose=1, shuffle=True, validation_split=0.2, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Using the Validation set for a sanity check\n",
    "The below code does the following things:\n",
    "\n",
    "* Load the best-yet model \n",
    "\n",
    "* load the validation images we've been supplied with\n",
    "* Generate masks for the validation images\n",
    "    * Creates a validation_masks_dir if there is none yet.\n",
    "    * Creates validation masks or loads them\n",
    "    * Creates patches for the validation set\n",
    "* Show side-by-side plots of the original validation image and the new mask\n",
    "\n",
    "* Shove one image in our best model and ask predict() what it makes out of it\n",
    "    * apply a threshold to the image\n",
    "* Plot the orgininal image, the defined mask, and the prediction side-by-side\n",
    "\n",
    "## 3.1 Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our best model\n",
    "model1 = keras.models.load_model('weights.h5') #saved by our callback earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Generate masks for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it does not exist already, create the validation masks folder\n",
    "validation_paths = os.listdir(validation_dir)\n",
    "if os.path.exists(validation_masks_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.system('mkdir -p ' + validation_masks_dir)\n",
    "\n",
    "# generate the masks if they are not already present on the system.\n",
    "mask_paths = os.listdir(validation_masks_dir)\n",
    "\n",
    "print('Found {} validation images.'.format(len(validation_paths))) # How many images do we actually have?\n",
    "\n",
    "for idx, path in enumerate(validation_paths):\n",
    "    mask_name = path.split('.png')[0] + '_mask.png'\n",
    "    if mask_name not in mask_paths:\n",
    "        print('Currently at image {}'.format(idx))\n",
    "        createMaskForImage(validation_dir, path, validation_points, validation_masks_dir, createCircularMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Generate patches for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vpatches = generate_patches(validation_dir, validation_masks_dir, 20, global_width, global_height, validation_points, True)\n",
    "vmask_patches = []\n",
    "vimg_patches = []\n",
    "for patch in vpatches:\n",
    "    vimg_patches.append(np.array(patch[0]))\n",
    "    vmask_patches.append(np.array(patch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_p = []\n",
    "for img in vimg_patches:\n",
    "    val_images_p.append(np.asarray(img[:, :, :]))\n",
    "    \n",
    "#sanity checks.. what sizes are we dealing with?\n",
    "print(len(val_images_p))\n",
    "print(np.shape(val_images_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Check patches and masks from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show validation image and it's mask - Another sanity check\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "print(vimg_patches[0].shape)\n",
    "plt.imshow(vimg_patches[1])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(vmask_patches[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Make a prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "preds_val = model1.predict(np.asarray(val_images_p), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Threshold prediction\n",
    "May need to find a better way to do this at some point.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amin(preds_val)) # prints min\n",
    "print(np.ptp(preds_val)) # prints range\n",
    "print(np.amax(preds_val)) # prints max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold prediction\n",
    "preds_val = np.squeeze(preds_val) \n",
    "preds_val_t = (preds_val > 0.5)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amin(preds_val_t)) # prints min\n",
    "print(np.ptp(preds_val_t)) # prints range\n",
    "print(np.amax(preds_val_t)) # prints max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Checking prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check for checking image size\n",
    "print(np.shape(vimg_patches[0]))\n",
    "print(np.shape(preds_val[0])) \n",
    "print(np.shape(preds_val_t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subplot of 1 row\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "plt.suptitle('Example of a prediction on the validation set', fontsize=16)\n",
    "\n",
    "idx = 1 \n",
    "\n",
    "# plot original image\n",
    "plt.subplot(151)\n",
    "print(vimg_patches[idx].shape)\n",
    "plt.imshow(vimg_patches[idx])\n",
    "plt.title('Input data')\n",
    "\n",
    "#plot what the mask should have been\n",
    "plt.subplot(152)\n",
    "print(vmask_patches[idx].shape)\n",
    "plt.imshow(vmask_patches[idx])\n",
    "plt.title('Actual mask')\n",
    "\n",
    "#plot raw, unthresholded prediction\n",
    "plt.subplot(153)\n",
    "print(preds_val[idx].shape)\n",
    "plt.imshow(preds_val[idx])\n",
    "plt.title('Un-thresholded prediction')\n",
    "\n",
    "#plot thresholded prediction\n",
    "plt.subplot(154)\n",
    "plt.imshow(preds_val_t[idx], cmap='gray')\n",
    "plt.title('Thresholded Prediction')\n",
    "\n",
    "#plot labels using the measure tools\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# what this does is label the different blobs based on the connected component principle\n",
    "labels = label(preds_val_t[idx], background=0)\n",
    "\n",
    "# it should show even the tiniest specks as different blobs, this is of course undesirable because these are false positives!\n",
    "plt.subplot(155)\n",
    "plt.imshow(labels, cmap='spectral')\n",
    "plt.title('Identification of different clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just another validation of what we're seeing\n",
    "regions = regionprops(labels)\n",
    "\n",
    "for region in regions:\n",
    "    print('Number of pixels in blob: '+ format(region.area))\n",
    "    print('centroid coordinates of blob: '+format(region.centroid))\n",
    "    print('extent '+format(region.extent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get full images and their titles\n",
    "test_names = os.listdir(test_dir)\n",
    "X_test = []\n",
    "print('found:' + format(len(test_names))) # number of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a quick sample from the test set.\n",
    "img = imread(join(test_dir,test_names[2]))\n",
    "print(img.shape)\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "img_p = feature_extraction.image.extract_patches_2d(img, (512, 512), max_patches=3)\n",
    "\n",
    "print(img_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the first two pics of the test data\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(format(test_names[0]))\n",
    "plt.imshow(img_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model1.predict(img_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresholding\n",
    "preds_test = np.squeeze(test_preds) \n",
    "preds_test_t = (preds_test > 0.5)*1.0\n",
    "print(test_preds.shape)\n",
    "print(preds_test.shape)\n",
    "print(preds_test_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subplot of 1 row\n",
    "plt.figure(1, figsize=(18, 6))\n",
    "plt.suptitle('Example of a prediction on the tes set', fontsize=16)\n",
    "\n",
    "# plot original image\n",
    "plt.subplot(141)\n",
    "plt.imshow(np.squeeze(img_p[0]))\n",
    "plt.title('Input data')\n",
    "\n",
    "#plot raw, unthresholded prediction\n",
    "plt.subplot(142)\n",
    "plt.imshow(preds_test[0])\n",
    "plt.title('Un-thresholded prediction')\n",
    "\n",
    "#plot thresholded prediction\n",
    "plt.subplot(143)\n",
    "plt.imshow(preds_test_t[0], cmap='gray')\n",
    "plt.title('Thresholded Prediction')\n",
    "\n",
    "# what this does is label the different blobs based on the connected component principle\n",
    "labels = label(preds_test_t[0], background=0)\n",
    "\n",
    "# it should show even the tiniest specks as different blobs, this is of course undesirable because these are false positives!\n",
    "plt.subplot(144)\n",
    "plt.imshow(labels, cmap='spectral')\n",
    "plt.title('Identification of different clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try getting the image through the prepareSubmissionData function\n",
    "#preds_test_t = np.expand_dims(preds_test_t, axis=2)\n",
    "df = prepareSubmissionData(test_names[1], preds_test_t)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print to see if it looks right\n",
    "df.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir for results\n",
    "result_dir = 'Results'\n",
    "# Create directory for the results (if not already existing)\n",
    "if os.path.exists(result_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.system('mkdir -p ' + result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"file.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Evaluation on the test set\n",
    "\n",
    "## 4.1 training on the training + validation set\n",
    "More data is more better. Lets take the validation set as training data for our final model and using a split of 0.1 or 0.2?\n",
    "\n",
    "Also worth to be considered is training on full images!\n",
    "\n",
    "## 4.2 Loading test images\n",
    "TODO\n",
    "\n",
    "## 4.3 Make predictions on the test images\n",
    "TODO\n",
    "\n",
    "## 4.4 Store test prediction images\n",
    "TODO\n",
    "\n",
    "## 4.5 Calculate Lymphocyte centroids\n",
    "TODO\n",
    "\n",
    "## 4.6 Convert predictions to a csv submission\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - What is outside the flow of work\n",
    "Counting the number of lymphocytes was the goal of the project although the evaluation is based on the precision of the network. Therefore the following method returns the number of lymphocytes, given a sample image. \n",
    "\n",
    "## 5.1 Counting Lymps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count the number of lymphocytes in a given image\n",
    "def count_lymps(image):\n",
    "    num = skimage.measure.label(image,  return_num=True)[1]\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets test this with a mask!\n",
    "print('number of blobs: '+format(count_lymps(vmask_patches[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and other things that come up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.999 Print the time needed to execute the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- The entire notebook was done in %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
