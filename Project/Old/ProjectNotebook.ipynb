{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISMI2018 Lymphocyte Detection Project\n",
    "This is the main notebook for the final ISMI2018 project.\n",
    "\n",
    "\n",
    "*Detection of lymphocytes in histopathology whole-slide images of breast, colon and prostate cancer, stained with immunohistochemistry*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team 6\n",
    "Our group consists out of four people:\n",
    "* **Brian Westerweel (Data Science)** - `B.Westerweel@student.ru.nl`\n",
    "* **Christoph Schmidl (Data Science)** - `c.schmidl@student.ru.nl`\n",
    "* **Gijs van der Meijde (Software Science)** - `G.vanderMeijde@student.ru.nl`\n",
    "* **Jeffrey Luppus (Data Science)** - `J.Luppes@student.ru.nl`\n",
    "\n",
    "*Supervisor: Francesco Ciompi*\n",
    "\n",
    "Group Github page: https://github.com/jeffluppes/ISMI2018 *feel free to work in branches.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals for this week (14 to 20 may)\n",
    "\n",
    "* Creating Masks\n",
    "* Implementation of U-net structure, apply it\n",
    "* Implement a patch generator\n",
    "* Implement rudimentary data augmentation\n",
    "* Figure out implementation of evaluation (and implement it, ;))\n",
    "\n",
    "Be aware of the following:\n",
    "\n",
    "* **Next contact moment**: e-mail to Francesco on Thursday. \n",
    "* **Next group meeting**: (Jeff): I'll mail Francesco on Thursday about setting one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Deadlines\n",
    "\n",
    "* **Mid-term presentation:** June 4, 9:00 - 12:00, room 616 Huygen building\n",
    "* **Final presentation:** July 2, 9:00 - 12:00, room 616 Huygen building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "The two papers Francesco sent:\n",
    "\n",
    "* https://openreview.net/pdf?id=rk0xLisiM\n",
    "* https://openreview.net/pdf?id=S10IfW2oz\n",
    "\n",
    "Kaggle Contest about cell detection (Data Science Bowl 2018)\n",
    "\n",
    "* https://www.kaggle.com/c/data-science-bowl-2018\n",
    "\n",
    "Particular Kernels of Interest (KoIs)\n",
    "\n",
    "* https://www.kaggle.com/weiji14/yet-another-keras-u-net-data-augmentation\n",
    "* https://www.kaggle.com/piotrczapla/tensorflow-u-net-starter-lb-0-34\n",
    "* https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277?scriptVersionId=2164855\n",
    "\n",
    "Other resources\n",
    "\n",
    "* https://towardsdatascience.com/medical-image-segmentation-part-1-unet-convolutional-networks-with-interactive-code-70f0f17f46c6 (Christoph)\n",
    "* https://colab.research.google.com/drive/1BgCDxVdVc0MAe_kC0waMGUV9ShcWW0hM (Christoph)\n",
    "* https://keunwoochoi.wordpress.com/2017/10/11/u-net-on-keras-2-0/ (Jeff)\n",
    "* https://github.com/jocicmarko/ultrasound-nerve-segmentation (Jeff)\n",
    "* https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/ (Gijs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "from os.path import join, basename, dirname, exists  \n",
    "import os  \n",
    "from glob import glob\n",
    "import csv\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Computational\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from matplotlib import pyplot as plt  \n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# Other\n",
    "from scipy.ndimage import imread  \n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General introduction\n",
    "TODO once more of this takes shape we should have some kind of general introduction here where we talk about the sections to come and how they relate to each other. It should be high-level and introductionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If the Jupter server runs on Cartesius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/train_images'\n",
    "validation_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/validation_images'\n",
    "test_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/test_images'\n",
    "train_points = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/training_annotations.csv'\n",
    "data_dir = '/home/ruc0030/proj_1/project_data'\n",
    "train_masks_dir = '/projects/0/ismi2018/FINALPROJECTS/LYMPHOCYTE_DETECTION/mask_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Circle Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    return x.split(', ')\n",
    "\n",
    "def createCircularMask(h, w, center, radius):\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "    \n",
    "\n",
    "def createMaskForImage(img_dir, image_path, center_csv, mask_dir, radius=6):\n",
    "    image_name = image_path.split('.png')[0]\n",
    "    image_id, roi = image_name.split('_ROI_')\n",
    "    print('Processing {}'.format(image_name))\n",
    "    \n",
    "    image = plt.imread(join(img_dir, image_path))\n",
    "    mask = np.zeros((image.shape[0], image.shape[1]))\n",
    "    \n",
    "    pois = []\n",
    "    with open(center_csv) as file:\n",
    "        pois = list(map(split, file.readlines()[1:]))\n",
    "    \n",
    "    pois = [poi for poi in pois if (poi[0] == image_id and poi[1] == roi)]\n",
    "\n",
    "    for poi in pois:\n",
    "        x = int(float(poi[3]))\n",
    "        y = int(float(poi[4]))\n",
    "        shape_mask = createCircularMask(image.shape[0], image.shape[1], [x, y], radius)\n",
    "        mask[shape_mask] = 1\n",
    "        \n",
    "    mask_image = Image.fromarray(np.uint8(mask*255), 'L')\n",
    "    mask_image.save(join(mask_dir, image_name + '_mask.png'))\n",
    "    print('Created a mask for: {}'.format(image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_paths = os.listdir(train_dir)\n",
    "mask_paths = os.listdir(train_masks_dir)\n",
    "for path in training_paths:\n",
    "    mask_name = path.split('.png')[0] + '_mask.png'\n",
    "    if mask_name not in mask_paths:\n",
    "        createMaskForImage(train_dir, path, train_points, train_masks_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have THE BEST patch generator, its true, its great. #MakeGijsGreatAgain\n",
    "\n",
    "#This function generates 1 random patch from patch_amount random images.\n",
    "def generate_patches(img_dir, msk_dir, patch_amount, width, height):\n",
    "    print(\"Generating {} batches of {}x{} from {}/*.png\".format(patch_amount,width,height,img_dir))\n",
    "    patches = []\n",
    "    all_img_paths = os.listdir(img_dir)\n",
    "    print(\"{} images found.\".format(len(all_img_paths)))\n",
    "    img_paths = random.sample(all_img_paths, patch_amount)\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "        img = imread(join(img_dir,img_path))\n",
    "        msk = imread(join(msk_dir,img_path.split(\".\")[0],\"_mask.png\"))\n",
    "        print(\"img {} dementions: {}\".format(img_path,img.shape))\n",
    "        patches.append(generate_patch(img,msk,width,height))\n",
    "        \n",
    "    return patches\n",
    "\n",
    "#This function generates a single random patch from an image.\n",
    "def generate_patch(img, msk, width, height):\n",
    "    img = np.pad(img, (0 if height < img.shape[1] else height-img.shape[1] , 0 if width < img.shape[0] else width-img.shape[0]), mode='constant')\n",
    "    img = np.pad(msk, (0 if height < img.shape[1] else height-img.shape[1] , 0 if width < img.shape[0] else width-img.shape[0]), mode='constant')\n",
    "    x = random.randint(0,img.shape[0]-width+1);\n",
    "    x1 = x + width\n",
    "    y = random.randint(0,img.shape[1]-height+1);\n",
    "    y1 = y + height\n",
    "    print(\"patch: {}x{}\".format(x,y))\n",
    "    return (img[x:x1,y:y1,:], msk[x:x1,y:y1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_patches(train_dir, train_masks_dir, 20, 512, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read images from disk and convert them to xyc format in a desire output range.\n",
    "def load_image(input_path, range_min=0, range_max=1):\n",
    "    \n",
    "    # Read image data (x, y, c) [0, 255]\n",
    "    image = Image.open(input_path)\n",
    "    \n",
    "    \n",
    "    half_the_width = image.size[0] / 2\n",
    "    half_the_height = image.size[1] / 2\n",
    "    image = image.crop(\n",
    "        (\n",
    "            half_the_width - 100,\n",
    "            half_the_height - 100,\n",
    "            half_the_width + 100,\n",
    "            half_the_height + 100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Convert image to the correct range\n",
    "    image = np.asarray(image) / 255\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define a function to plot a batch or list of image patches in a grid\n",
    "def plot_image(images, images_per_row=8):\n",
    "    \n",
    "    fig, axs = plt.subplots(int(np.ceil(len(images)/images_per_row)), images_per_row)\n",
    "    \n",
    "    c = 0\n",
    "    for ax_row in axs:\n",
    "        for ax in ax_row:\n",
    "            if c < len(images):\n",
    "                ax.imshow(images[c])\n",
    "            ax.axis('off')            \n",
    "            c += 1\n",
    "    plt.show()\n",
    "    \n",
    "training_paths = os.listdir(train_dir)\n",
    "validation_paths = os.listdir(validation_dir)\n",
    "\n",
    "training_images = [load_image(join(train_dir, path)) for path in training_paths[:50]]\n",
    "print('Some training examples (shape {shape}):'.format(shape=training_images[0].shape))\n",
    "plot_image(training_images[12:16], images_per_row=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=90,\n",
    "                                     horizontal_flip=True, \n",
    "                                     vertical_flip=True, \n",
    "                                     zoom_range=0.3, \n",
    "                                     width_shift_range=.3, \n",
    "                                     height_shift_range=.3)\n",
    "\n",
    "fake_labels = np.random.rand(len(training_images))\n",
    "fake_labels[fake_labels >= .5] = 1\n",
    "fake_labels[fake_labels < .5] = 0\n",
    "\n",
    "datagen.fit(training_images)\n",
    "\n",
    "for X_batch, y_batch in datagen.flow(np.array(training_images), fake_labels, batch_size=9):\n",
    "    plot_image(X_batch, images_per_row=3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a stub.\n",
    "\n",
    "def unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
